{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# from osim.env import ProstheticsEnv\n",
    "from prosthetics_env_with_history import ProstheticsEnvWithHistory\n",
    "from td3 import TD3\n",
    "# from replay_buffer import ReplayBuffer\n",
    "from env_history_sampler import EnvHistorySampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"env\": {\n",
    "        \"integrator_accuracy\": 2e-3,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"architecture\": \"TD3\",\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"episode_save_load_file\": \"prosthetics_env_history.h5\",\n",
    "        \"checkpoint_save_load_prefix\": \"checkpoint_TD3\",\n",
    "        \"start_timesteps\": 5e3, # How many time steps purely random policy is run for\n",
    "        \"eval_freq\": 5e3, # How often (time steps) we evaluate\n",
    "        \"max_timesteps\": 1e6, # Max time steps to train for\n",
    "        \"max_episode_steps\": 300, # Max number of steps to run for a single episode\n",
    "        \"expl_noise\": 0.5, # Std of Gaussian exploration noise  # was 0.1\n",
    "        \"batch_size\": 100, # Batch size for both actor and critic\n",
    "        \"discount\": 0.99, # Discount factor\n",
    "        \"tau\": 0.005, # Target network update rate\n",
    "        \"policy_noise\": 0.2, # Noise added to target policy during critic update\n",
    "        \"noise_clip\": 0.5, # Range to clip target policy noise\n",
    "        \"policy_freq\": 2, # Frequency of delayed policy updates\n",
    "        \"frameskip\": 5, # Max Frameskip steps\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path('.')\n",
    "LOGS_DIR = OUTPUT_DIR/'logs'\n",
    "CHECKPOINTS_DIR = OUTPUT_DIR/'checkpoints'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation Hacking\n",
    "\n",
    "- Rewrite all joint_pos, body_pos to be relative to mass_center_pos\n",
    "- Subtract mass_center_vel and mass_center_acc from joint_vel, body_vel, joint_acc, body_acc?\n",
    "- Either compute jounce/snap, or pass multiple timesteps, or just pass acceleration from past 3 timesteps?\n",
    "\n",
    "Initial Env Observation:\n",
    "```\n",
    "{\n",
    "    'joint_pos': {\n",
    "        'ground_pelvis': [0.0, 0.0, 0.0, 0.0, 0.94, 0.0],\n",
    "        'hip_r': [0.0, 0.0, 0.0],\n",
    "        'knee_r': [0.0],\n",
    "        'ankle_r': [0.0],\n",
    "        'hip_l': [0.0, 0.0, 0.0],\n",
    "        'knee_l': [0.0],\n",
    "        'ankle_l': [0.0],\n",
    "        'subtalar_l': [],\n",
    "        'mtp_l': [],\n",
    "        'back': [-0.0872665],\n",
    "        'back_0': []\n",
    "    },\n",
    "    'joint_vel': {\n",
    "        'ground_pelvis': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        'hip_r': [0.0, 0.0, 0.0],\n",
    "        'knee_r': [0.0],\n",
    "        'ankle_r': [0.0],\n",
    "        'hip_l': [0.0, 0.0, 0.0],\n",
    "        'knee_l': [0.0],\n",
    "        'ankle_l': [0.0],\n",
    "        'subtalar_l': [],\n",
    "        'mtp_l': [],\n",
    "        'back': [0.0],\n",
    "        'back_0': []\n",
    "    },\n",
    "    'joint_acc': {\n",
    "        'ground_pelvis': [34.07237489546962, 3.219284560937942, 0.021285761200362296, 13.997154494145377, 0.8655672359505977, -0.6156967622871027],\n",
    "        'hip_r': [-194.74323476194263, -4.441803696780512, 1.5931700403370996e-14],\n",
    "        'knee_r': [305.46152469620915],\n",
    "        'ankle_r': [9636.363025843913],\n",
    "        'hip_l': [-208.86020665024324, 3.5702556374966354, -4.2521541843143495e-14],\n",
    "        'knee_l': [399.3192427973721],\n",
    "        'ankle_l': [809.4478175113452],\n",
    "        'subtalar_l': [],\n",
    "        'mtp_l': [],\n",
    "        'back': [-2.3092638912203256e-14],\n",
    "        'back_0': []\n",
    "    },\n",
    "    'body_pos': {\n",
    "        'pelvis': [0.0, 0.94, 0.0],\n",
    "        'femur_r': [-0.0707, 0.8738999999999999, 0.0835],\n",
    "        'pros_tibia_r': [-0.07519985651753601, 0.47807930355164957, 0.0835],\n",
    "        'pros_foot_r': [-0.07519985651753601, 0.04807930355164958, 0.0835],\n",
    "        'femur_l': [-0.0707, 0.8738999999999999, -0.0835],\n",
    "        'tibia_l': [-0.07519985651753601, 0.47807930355164957, -0.0835],\n",
    "        'talus_l': [-0.07519985651753601, 0.04807930355164958, -0.0835],\n",
    "        'calcn_l': [-0.123969856517536, 0.006129303551649576, -0.09142],\n",
    "        'toes_l': [0.05483014348246398, 0.004129303551649576, -0.0925],\n",
    "        'torso': [-0.1007, 1.0214999999999999, 0.0],\n",
    "        'head': [-0.052764320996907754, 1.5694070821576522, 0.0]\n",
    "    },\n",
    "    'body_vel': {\n",
    "        'pelvis': [0.0, 0.0, 0.0],\n",
    "        'femur_r': [0.0, 0.0, 0.0],\n",
    "        'pros_tibia_r': [0.0, 0.0, 0.0],\n",
    "        'pros_foot_r': [0.0, 0.0, 0.0],\n",
    "        'femur_l': [0.0, 0.0, 0.0],\n",
    "        'tibia_l': [0.0, 0.0, 0.0],\n",
    "        'talus_l': [0.0, 0.0, 0.0],\n",
    "        'calcn_l': [0.0, 0.0, 0.0],\n",
    "        'toes_l': [0.0, 0.0, 0.0],\n",
    "        'torso': [0.0, 0.0, 0.0],\n",
    "        'head': [0.0, 0.0, 0.0]\n",
    "    },\n",
    "    'body_acc': {\n",
    "        'pelvis': [13.997154494145377, 0.8655672359505977, -0.6156967622871027],\n",
    "        'femur_r': [16.25111583579615, -1.812159929997423, -0.826986568448235],\n",
    "        'pros_tibia_r': [-49.070641675940735, 0.12065763836075294, -0.34299240980632545],\n",
    "        'pros_foot_r': [13.18934420084581, 0.12065763836075294, 0.18269081860597952],\n",
    "        'femur_l': [16.24756111367569, -1.2745394083207864, -0.826986568448235],\n",
    "        'tibia_l': [-55.19198970892064, 1.093538716356541, -0.6879691696202773],\n",
    "        'talus_l': [41.356517039396714, 1.093538716356541, -0.537051606700039],\n",
    "        'calcn_l': [84.73177709400595, -49.336407951145645, -0.5212902634646581],\n",
    "        'toes_l': [86.79971256249173, 135.5386990655368, -0.5243942154141731],\n",
    "        'torso': [11.220255940164602, -2.565520916023193, -0.35118159441778396],\n",
    "        'head': [-7.448239570993795, -0.9322384901609437, 1.4116668685846663]\n",
    "    },\n",
    "    'body_pos_rot': {\n",
    "        'pelvis': [-0.0, 0.0, -0.0],\n",
    "        'femur_r': [-0.0, 0.0, -0.0],\n",
    "        'pros_tibia_r': [-0.0, 0.0, -0.0],\n",
    "        'pros_foot_r': [-0.0, 0.0, -0.0],\n",
    "        'femur_l': [-0.0, 0.0, -0.0],\n",
    "        'tibia_l': [-0.0, 0.0, -0.0],\n",
    "        'talus_l': [-0.0, 0.0, -0.0],\n",
    "        'calcn_l': [-0.0, 0.0, -0.0],\n",
    "        'toes_l': [-0.0, 0.0, -0.0],\n",
    "        'torso': [-0.0, 0.0, -0.0872665],\n",
    "        'head': [-0.0, 0.0, -0.0872665]\n",
    "    },\n",
    "    'body_vel_rot': {\n",
    "        'pelvis': [0.0, 0.0, 0.0],\n",
    "        'femur_r': [0.0, 0.0, 0.0],\n",
    "        'pros_tibia_r': [0.0, 0.0, 0.0],\n",
    "        'pros_foot_r': [0.0, 0.0, 0.0],\n",
    "        'femur_l': [0.0, 0.0, 0.0],\n",
    "        'tibia_l': [0.0, 0.0, 0.0],\n",
    "        'talus_l': [0.0, 0.0, 0.0],\n",
    "        'calcn_l': [0.0, 0.0, 0.0],\n",
    "        'toes_l': [0.0, 0.0, 0.0],\n",
    "        'torso': [0.0, 0.0, 0.0],\n",
    "        'head': [0.0, 0.0, 0.0]\n",
    "    },\n",
    "    'body_acc_rot': {\n",
    "        'pelvis': [3.219284560937942, 0.021285761200362296, 34.07237489546962],\n",
    "        'femur_r': [-1.2225191358425698, 0.021285761200378228, -160.670859866473],\n",
    "        'pros_tibia_r': [-1.2225191358425698, 0.021285761200378228, 144.79066482973616],\n",
    "        'pros_foot_r': [-1.2225191358425698, 0.021285761200378228, 9781.15369067365],\n",
    "        'femur_l': [-0.35097107655869353, 0.021285761200404818, -174.7878317547736],\n",
    "        'tibia_l': [-0.35097107655869353, 0.021285761200404818, 224.5314110425985],\n",
    "        'talus_l': [-0.35097107655869353, 0.021285761200404818, 1033.9792285539438],\n",
    "        'calcn_l': [-0.35097107655869353, 0.021285761200404818, 1033.9792285539438],\n",
    "        'toes_l': [-0.35097107655869353, 0.021285761200404818, 1033.9792285539438],\n",
    "        'torso': [3.219284560937942, 0.021285761200362296, 34.0723748954696],\n",
    "        'head': [3.219284560937942, 0.021285761200362296, 34.0723748954696]\n",
    "    },\n",
    "    'forces': {\n",
    "        'abd_r': [219.6613927253564],\n",
    "        'add_r': [144.87433100305103],\n",
    "        'hamstrings_r': [194.30030504346755],\n",
    "        'bifemsh_r': [42.728811234363775],\n",
    "        'glut_max_r': [171.7873509605573],\n",
    "        'iliopsoas_r': [158.01207984383657],\n",
    "        'rect_fem_r': [99.0329705435046],\n",
    "        'vasti_r': [436.79388413623326],\n",
    "        'abd_l': [219.6613927253564],\n",
    "        'add_l': [144.87433100305103],\n",
    "        'hamstrings_l': [194.30030504346755],\n",
    "        'bifemsh_l': [42.728811234363775],\n",
    "        'glut_max_l': [171.7873509605573],\n",
    "        'iliopsoas_l': [158.01207984383657],\n",
    "        'rect_fem_l': [99.0329705435046],\n",
    "        'vasti_l': [436.79388413623326],\n",
    "        'gastroc_l': [273.0178325689043],\n",
    "        'soleus_l': [370.0059951709156],\n",
    "        'tib_ant_l': [104.05059952034294],\n",
    "        'ankleSpring': [-0.0],\n",
    "        'pros_foot_r_0': [-1.3573320551122304e-12, -388.7553514927188, 0.0, 32.46107184964201, -1.1333722660187127e-13, 3.726164264482634, 1.3573320551122304e-12, 388.7553514927188, 0.0, 0.0, 0.0, 25.50818238819416, 1.3573320551122304e-12, 388.7553514927188, 0.0, 0.0, 0.0, 25.50818238819416],\n",
    "        'foot_l': [-1.7615592933859115e-12, -504.53063397142085, 0.0, -46.45915575255036, 1.622112753284362e-13, -4.943148065393853, 6.786660275561278e-13, 194.37767574636297, 0.0, 0.0, 0.0, 5.831330272390875, 1.0828932658297836e-12, 310.1529582250579, 0.0, 0.0, 0.0, 6.203059164501164, 1.0828932658297836e-12, 310.1529582250579, 0.0, 0.0, 0.0, 6.203059164501164],\n",
    "        'HipLimit_r': [0.0, 0.0],\n",
    "        'HipLimit_l': [0.0, 0.0],\n",
    "        'KneeLimit_r': [-0.0, 0.0],\n",
    "        'KneeLimit_l': [-0.0, 0.0],\n",
    "        'AnkleLimit_r': [0.0, 0.0],\n",
    "        'AnkleLimit_l': [0.0, 0.0],\n",
    "        'HipAddLimit_r': [0.0, 0.0],\n",
    "        'HipAddLimit_l': [0.0, 0.0]\n",
    "    },\n",
    "    'muscles': {\n",
    "        'abd_r': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.07752306863700548,\n",
    "            'fiber_velocity': 1.1700156898117815e-13,\n",
    "            'fiber_force': 219.6613927253564\n",
    "        },\n",
    "        'add_r': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.05526137592854144,\n",
    "            'fiber_velocity': 5.531257930905764e-11,\n",
    "            'fiber_force': 146.25768888087705\n",
    "        },\n",
    "        'hamstrings_r': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.06355896214015513,\n",
    "            'fiber_velocity': 2.1056261406660054e-14,\n",
    "            'fiber_force': 202.45627069225887\n",
    "        },\n",
    "        'bifemsh_r': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.13434264681417835,\n",
    "            'fiber_velocity': 9.542198984660805e-17,\n",
    "            'fiber_force': 45.09919197278584\n",
    "        },\n",
    "        'glut_max_r': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.16084824667171801,\n",
    "            'fiber_velocity': 1.0181982508865008e-12,\n",
    "            'fiber_force': 171.7873509605573\n",
    "        },\n",
    "        'iliopsoas_r': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.13005768603600326,\n",
    "            'fiber_velocity': 3.347183497651294e-11,\n",
    "            'fiber_force': 159.26525950285387\n",
    "        },\n",
    "        'rect_fem_r': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.06027044615978444,\n",
    "            'fiber_velocity': 2.2362024955832438e-15,\n",
    "            'fiber_force': 99.63652479982161\n",
    "        },\n",
    "        'vasti_r': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.07890756873654925,\n",
    "            'fiber_velocity': 6.168233828156989e-15,\n",
    "            'fiber_force': 437.7385693769557\n",
    "        },\n",
    "        'abd_l': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.07752306863700548,\n",
    "            'fiber_velocity': 1.1700156898117815e-13,\n",
    "            'fiber_force': 219.6613927253564\n",
    "        },\n",
    "        'add_l': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.05526137592854144,\n",
    "            'fiber_velocity': 5.531257930905764e-11,\n",
    "            'fiber_force': 146.25768888087705\n",
    "        },\n",
    "        'hamstrings_l': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.06355896214015513,\n",
    "            'fiber_velocity': 2.1056261406660054e-14,\n",
    "            'fiber_force': 202.45627069225887\n",
    "        },\n",
    "        'bifemsh_l': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.13434264681417835,\n",
    "            'fiber_velocity': 9.542198984660805e-17,\n",
    "            'fiber_force': 45.09919197278584\n",
    "        },\n",
    "        'glut_max_l': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.16084824667171801,\n",
    "            'fiber_velocity': 1.0181982508865008e-12,\n",
    "            'fiber_force': 171.7873509605573\n",
    "        },\n",
    "        'iliopsoas_l': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.13005768603600326,\n",
    "            'fiber_velocity': 3.347183497651294e-11,\n",
    "            'fiber_force': 159.26525950285387\n",
    "        },\n",
    "        'rect_fem_l': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.06027044615978444,\n",
    "            'fiber_velocity': 2.2362024955832438e-15,\n",
    "            'fiber_force': 99.63652479982161\n",
    "        },\n",
    "        'vasti_l': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.07890756873654925,\n",
    "            'fiber_velocity': 6.168233828156989e-15,\n",
    "            'fiber_force': 437.7385693769557\n",
    "        },\n",
    "        'gastroc_l': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.05720257668702345,\n",
    "            'fiber_velocity': 5.718949639274886e-14,\n",
    "            'fiber_force': 282.79456495087237\n",
    "        },\n",
    "        'soleus_l': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.04494814124106819,\n",
    "            'fiber_velocity': 3.4120643802478774e-10,\n",
    "            'fiber_force': 406.4161372187392\n",
    "        },\n",
    "        'tib_ant_l': {\n",
    "            'activation': 0.05,\n",
    "            'fiber_length': 0.06288000983990409,\n",
    "            'fiber_velocity': 8.525642140971546e-14,\n",
    "            'fiber_force': 104.5158690359632\n",
    "        }\n",
    "    },\n",
    "    'markers': {},\n",
    "    'misc': {\n",
    "        'mass_center_pos': [-0.08466565561225976, 0.9952730567231536, -0.003576087446004414],\n",
    "        'mass_center_vel': [0.0, 0.0, 0.0],\n",
    "        'mass_center_acc': [4.4008799039045146e-14, 2.570832209970726, -1.0237645330147003e-15]\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied & modified from https://github.com/stanfordnmbl/osim-rl/blob/master/osim/env/osim.py#L452\n",
    "def single_step_env_obs_to_model_obs(env_obs, target_vel=[3,0,0], include_lower_order_values=True):\n",
    "    env_obs = env_obs.copy()\n",
    "    has_prosthetic = 'pros_foot_r' in env_obs['body_pos']\n",
    "\n",
    "    target_vel_x = target_vel[0]\n",
    "    target_vel_z = target_vel[2]\n",
    "    eps = 1e-8\n",
    "\n",
    "    frame = {\n",
    "        'pos': np.array(env_obs['misc']['mass_center_pos']),\n",
    "        'vel': np.array(env_obs['misc']['mass_center_vel']),\n",
    "        'acc': np.array(env_obs['misc']['mass_center_acc']),\n",
    "    }\n",
    "\n",
    "    # Transform reference frame from 0,0,0 to center of mass:\n",
    "    for k, pos in env_obs['body_pos'].items():\n",
    "        env_obs['body_pos'][k] = list(np.array(pos) - frame['pos'])\n",
    "    for k, vel in env_obs['body_vel'].items():\n",
    "        env_obs['body_vel'][k] = list(np.array(vel) - frame['vel'])\n",
    "    for k, acc in env_obs['body_acc'].items():\n",
    "        env_obs['body_acc'][k] = list(np.array(acc) - frame['acc'])\n",
    "\n",
    "    # Normalize body vel/acc based on center of mass vel/acc:\n",
    "#     for k, vel in env_obs['body_vel'].items():\n",
    "#         env_obs['body_vel'][k] = list(np.array(vel) / (frame['vel'] + eps))\n",
    "#     for k, acc in env_obs['body_acc'].items():\n",
    "#         env_obs['body_acc'][k] = list(np.array(acc) / (frame['acc'] + eps))\n",
    "\n",
    "    # Collect observation vector\n",
    "    lower_order = []\n",
    "    highest_order = []    \n",
    "    for body_part in [\"head\",\"torso\",\"pelvis\",\"femur_l\",\"femur_r\",\"tibia_l\",\"tibia_r\",\"pros_tibia_r\",\"talus_l\",\"talus_r\",\"toes_l\",\"toes_r\",\"pros_foot_r\",\"calcn_l\",\"calcn_r\"]:\n",
    "        if has_prosthetic and body_part in [\"toes_r\",\"tibia_r\",\"talus_r\",\"calcn_r\"]:\n",
    "            lower_order += [0] * 12\n",
    "            highest_order += [0] * 6\n",
    "            continue\n",
    "        if not has_prosthetic and body_part in [\"pros_foot_r\",\"pros_tibia_r\"]:\n",
    "            lower_order += [0] * 12\n",
    "            highest_order += [0] * 6\n",
    "            continue\n",
    "        lower_order += env_obs[\"body_pos\"][body_part][0:2]\n",
    "        lower_order += env_obs[\"body_vel\"][body_part][0:2]\n",
    "        highest_order += env_obs[\"body_acc\"][body_part][0:2]\n",
    "        lower_order += env_obs[\"body_pos_rot\"][body_part][0:2]\n",
    "        lower_order += env_obs[\"body_vel_rot\"][body_part][0:2]\n",
    "        highest_order += env_obs[\"body_acc_rot\"][body_part][0:2]\n",
    "\n",
    "    for joint in [\"ground_pelvis\",\"ankle_l\",\"ankle_r\",\"back\",\"hip_l\",\"hip_r\",\"knee_l\",\"knee_r\"]:\n",
    "        lower_order += env_obs[\"joint_pos\"][joint]\n",
    "        lower_order += env_obs[\"joint_vel\"][joint]\n",
    "        highest_order += env_obs[\"joint_acc\"][joint]\n",
    "\n",
    "    for muscle in sorted(env_obs[\"muscles\"].keys()):\n",
    "        highest_order += [env_obs[\"muscles\"][muscle][\"activation\"]]\n",
    "        highest_order += [env_obs[\"muscles\"][muscle][\"fiber_length\"]]\n",
    "        highest_order += [env_obs[\"muscles\"][muscle][\"fiber_velocity\"]]\n",
    "        highest_order += [env_obs[\"muscles\"][muscle][\"fiber_force\"]]\n",
    "\n",
    "    for force in ['abd_l', 'add_l', 'hamstrings_l', 'bifemsh_l', 'glut_max_l', 'iliopsoas_l', 'rect_fem_l', 'vasti_l', 'gastroc_l', 'soleus_l', 'tib_ant_l', 'ankleSpring', 'pros_foot_r_0', 'foot_l', 'HipLimit_l', 'KneeLimit_l', 'AnkleLimit_l', 'HipAddLimit_l']:\n",
    "        highest_order += env_obs['forces'][force]\n",
    "        if not '_l' in force:\n",
    "            continue\n",
    "        force = force.replace('_l', '_r')\n",
    "        if has_prosthetic:\n",
    "            if force in ['gastroc_r', 'soleus_r', 'tib_ant_r']:\n",
    "                highest_order += [0]\n",
    "                continue\n",
    "            if force in ['foot_r']:\n",
    "                highest_order += [0] * 24\n",
    "                continue\n",
    "        else:\n",
    "            if force in ['pros_foot_r_0']:\n",
    "                highest_order += [0] * 18\n",
    "                continue\n",
    "        highest_order += env_obs['forces'][force.replace('_l', '_r')]\n",
    "\n",
    "    # Center of mass\n",
    "    lower_order += list(frame['pos'])\n",
    "    lower_order += list(frame['vel'])\n",
    "    highest_order += list(frame['acc'])\n",
    "\n",
    "    # Target velocity\n",
    "    highest_order += [frame['vel'][0] - target_vel_x, frame['vel'][2] - target_vel_z]\n",
    "\n",
    "    result = highest_order\n",
    "    if include_lower_order_values:\n",
    "        result = lower_order + result\n",
    "    return result\n",
    "\n",
    "def env_obs_history_to_model_obs(env_obs_history):\n",
    "    env_obs_history = env_obs_history[-4:]\n",
    "    # Duplicate first env_obs to ensure we have at least 4 steps of history.\n",
    "    env_obs_history = env_obs_history[:1] * (4 - len(env_obs_history)) + env_obs_history\n",
    "\n",
    "    model_obs_steps = [single_step_env_obs_to_model_obs(env_obs_history[-1])]\n",
    "    model_obs_steps += [single_step_env_obs_to_model_obs(env_obs, include_lower_order_values=False) for env_obs in env_obs_history[:-1]][::-1]\n",
    "    return np.concatenate(model_obs_steps)\n",
    "\n",
    "\n",
    "def prepare_model_observation(env):\n",
    "    df_history = env.history(current_episode_only=True)\n",
    "    model_obs = env_obs_history_to_model_obs(df_history['obs'].tolist())\n",
    "    return model_obs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action hacking\n",
    "\n",
    "- binary activations?  Or several \"bins\"?\n",
    "- Frameskip?\n",
    "- Muscles must remain \"active\" for at least 10 frames once activated?  Randomized?\n",
    "- Limited number of muscles can fire at one time?\n",
    "- Handle prosthetic or not (strip activations of nonexistent muscles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_state = {}\n",
    "\n",
    "def reset_frameskip(n=8):\n",
    "    action_state['n_frameskip'] = n\n",
    "    action_state['frames_to_skip'] = 0  # Start at 0 so we don't skip the first model action.\n",
    "    action_state['frameskip_action'] = None\n",
    "    \n",
    "def apply_frameskip(model_action):\n",
    "    if action_state.get('frames_to_skip', 0) == 0:\n",
    "        # Already skipped enough frames.  Reset counter & cache unskipped frame.\n",
    "        action_state['frames_to_skip'] = np.random.randint(action_state.get('n_frameskip', 0) + 1)\n",
    "        action_state['frameskip_action'] = model_action\n",
    "    else:\n",
    "        # Need to skip this frame.  Decrement the counter & apply the cached unskipped frame.\n",
    "        action_state['frames_to_skip'] -= 1\n",
    "        model_action = action_state.get('frameskip_action')\n",
    "    return model_action\n",
    "\n",
    "\n",
    "def prepare_env_action(model_action):\n",
    "    # model_action is a list of muscle activations\n",
    "\n",
    "    # Frame skipping\n",
    "    model_action = apply_frameskip(model_action)\n",
    "\n",
    "    model_action = np.array(model_action)\n",
    "\n",
    "    # Binarize the muscle activations\n",
    "    model_action = model_action.round()\n",
    "    \n",
    "    return model_action.tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Hacking\n",
    "\n",
    "- Survival reward\n",
    "- Lean forward reward (to avod models which had torso too upright) (may need to be based on speed)\n",
    "- Reward for minimizing sideways velocity?\n",
    "- Reward for minimizing vertical velocity (COG)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_obs_to_custom_reward(obs):\n",
    "    if type(obs) != dict:\n",
    "        raise ValueError('obs must be a dict (project=False)')\n",
    "\n",
    "    target_vel_x = 3\n",
    "    target_vel_z = 0\n",
    "    eps = 1e-8\n",
    "\n",
    "    target_vel_theta = -np.arctan(target_vel_z/(target_vel_x+eps)) if target_vel_x >= 0 else np.pi - np.arctan(target_vel_z/(target_vel_x+eps))\n",
    "\n",
    "    # Parabolic reward/penalty for tracking a target value within some tolerance. \n",
    "    # Unit reward: 1 at target value, 0 at `tolerance` distance from target value, negative outside of `tolerance`.\n",
    "    # Multiply by desired scale factor / magnitude. Don't multiply by too large of a scale factor — it also amplifies the slope.\n",
    "    # Make the tolerance bigger than you think — it makes the slope more gradual / less severe.\n",
    "    # `tolerance`: reward is positive if within `tolerance` of target value, else negative.\n",
    "    val_diff_reward = lambda val, target, tolerance: (1 - ((val - target)/tolerance)**2)\n",
    "    def radians_diff_wrapped(a1, a2):\n",
    "        # Make both angles within (-2pi, 2pi)\n",
    "        a1, a2 = a1 % (2*np.pi), a2 % (2*np.pi)\n",
    "        # Make both angles positive -- within [0, 2pi)\n",
    "        a1 = a1 + 2*np.pi if a1 < 0 else a1\n",
    "        a2 = a2 + 2*np.pi if a2 < 0 else a2\n",
    "        # Make a1 the smaller angle\n",
    "        a1, a2 = min(a1, a2), max(a1, a2)\n",
    "        # Make sure a1 is within pi of a2 — two angles can't be greater than pi apart in relative (wrapped) sense.\n",
    "        a1 = a1 + 2*np.pi if a2 - a1 > np.pi else a1\n",
    "        return np.fabs(a2 - a1)\n",
    "    \n",
    "    avg_knee_joint_pos = (obs['joint_pos']['knee_l'][0] + obs['joint_pos']['knee_r'][0]) / 2\n",
    "    target_avg_knee_joint_pos = 60*np.pi/180\n",
    "    \n",
    "    rewards = {\n",
    "        'survival': 100,\n",
    "        'target_velocity_x': 3 * val_diff_reward(obs['misc']['mass_center_vel'][0], target_vel_x, 5), # 3 at target velocity, 0 at 3m/s off-target, then negative\n",
    "        'target_velocity_z': 3 * val_diff_reward(obs['misc']['mass_center_vel'][2], target_vel_z, 5), # 3 at target velocity, 0 at 3m/s off-target, then negative\n",
    "        'head_velocity_x': 2 * val_diff_reward(obs['body_vel']['head'][0], target_vel_x, 5), # 2 at target velocity, 0 at 3m/s off-target, then negative\n",
    "        'head_velocity_z': 2 * val_diff_reward(obs['body_vel']['head'][2], target_vel_z, 5), # 2 at target velocity, 0 at 3m/s off-target, then negative\n",
    "        'lean_forward_x': 5 * val_diff_reward(obs['body_pos']['head'][0] - obs['body_pos']['pelvis'][0], .1 * target_vel_x, .4), # head in front of pelvis from perspective of velocity vector\n",
    "        'lean_forward_z': 5 * val_diff_reward(obs['body_pos']['head'][2] - obs['body_pos']['pelvis'][2], .1 * target_vel_z, .4), # head in front of pelvis from perspective of velocity vector\n",
    "        'hips_squared': 5 * val_diff_reward(radians_diff_wrapped(target_vel_theta, obs['body_pos_rot']['pelvis'][1]), 0, np.pi),\n",
    "        'knee_bent_l': 5 * val_diff_reward(obs['joint_pos']['knee_l'][0], target_avg_knee_joint_pos, np.pi), # goal range of roughly [0,120] degrees\n",
    "        'knee_bent_r': 5 * val_diff_reward(obs['joint_pos']['knee_r'][0], target_avg_knee_joint_pos, np.pi), # goal range of roughly [0,120] degrees\n",
    "        'low_y_vel_pelvis': 5 * val_diff_reward(obs['body_vel']['pelvis'][1], 0, 1),\n",
    "        'low_y_vel_head': 5 * val_diff_reward(obs['body_vel']['head'][1], 0, 1),\n",
    "        'low_y_vel_toes_l': 5 * val_diff_reward(obs['body_vel']['toes_l'][1], 0, 1),\n",
    "        'low_y_vel_pros_foot_r': 5 * val_diff_reward(obs['body_vel']['pros_foot_r'][1], 0, 1),\n",
    "        'knees_opposite_joint_vel': 0 if avg_knee_joint_pos < (target_avg_knee_joint_pos - 15*np.pi/180) else 3 * val_diff_reward(obs['joint_vel']['knee_l'][0], -obs['joint_vel']['knee_r'][0], np.pi), # The left knee should be opening when the right knee is closing, and vice versa\n",
    "        'feet_behind_mass_x': 5 * val_diff_reward(obs['misc']['mass_center_pos'][0] - (obs['body_pos']['toes_l'][0] + obs['body_pos']['pros_foot_r'][0])/2, .1 * target_vel_x, .4),\n",
    "        'feet_behind_mass_z': 5 * val_diff_reward(obs['misc']['mass_center_pos'][2] - (obs['body_pos']['toes_l'][2] + obs['body_pos']['pros_foot_r'][2])/2, .1 * target_vel_z, .4),\n",
    "        'one_foot_off_ground': 0,\n",
    "        'femurs_parallel': 0,\n",
    "        'absolute_foot_velocity': 0, # should be 0 at ground, 2x body velocity above ground\n",
    "        'forefoot_strike': 0,\n",
    "    }    \n",
    "\n",
    "#     if should_abort_episode(obs, custom_rewards=rewards):\n",
    "#         rewards['abort_episode'] = -100\n",
    "\n",
    "    return rewards\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode Hacking (Custom \"done\" criteria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_abort_episode(env_obs, custom_rewards=None, verbose=False):\n",
    "#     print((np.array(env_obs['body_pos_rot']['torso'])*180/math.pi > 60).any())\n",
    "#     if env_obs['body_pos_rot']['torso'][2] < -0.2:\n",
    "#         return True\n",
    "    rewards = custom_rewards if custom_rewards != None else env_obs_to_custom_reward(env_obs)\n",
    "    # print(f'Custom reward: {sum(rewards.values())}')\n",
    "    if (env_obs['body_pos']['head'][0] - env_obs['body_pos']['pelvis'][0]) < -.2:\n",
    "        if verbose: print(f'Aborting episode due to head being > .2m behind the pelvis ({env_obs[\"body_pos\"][\"head\"][0] - env_obs[\"body_pos\"][\"pelvis\"][0]}).')\n",
    "        return True\n",
    "    if np.fabs(env_obs['body_pos']['head'][2]) > 0.5:\n",
    "        if verbose: print(f'Aborting episode due to head being > 0.5m away from centerline ({env_obs[\"body_pos\"][\"head\"][2]}).')\n",
    "        return True\n",
    "    if sum(rewards.values()) < -10:\n",
    "        if verbose:\n",
    "            print(f'Aborting episode due to custom reward < -10 ({sum(rewards.values())}):')\n",
    "            for k,v in rewards.items():\n",
    "                if v < 0:\n",
    "                    print(f'  reward `{k}` = {v}')\n",
    "        return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs policy for X episodes and returns average reward\n",
    "def evaluate_episode(policy):\n",
    "    obs = env.reset(**env_step_kwargs)\n",
    "#     obs = env.reset(**env_step_kwargs)\n",
    "    reset_frameskip(0)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action = policy.select_action(prepare_model_observation(env))\n",
    "        action = prepare_env_action(action)\n",
    "        obs, reward, done, _ = env.step(action, **env_step_kwargs)\n",
    "        \n",
    "        # We don't use the custom rewards here because we want to evaluate our progress against the environment's reward.\n",
    "        # obs_dict = env.get_state_desc()\n",
    "        # custom_rewards = compute_rewards(obs_dict)\n",
    "        # total_rewared += reward + sum(custom_rewards.values())\n",
    "\n",
    "        total_reward += reward\n",
    "    return total_reward\n",
    "\n",
    "def evaluate_policy(policy, eval_episodes=10):\n",
    "    avg_reward = 0.\n",
    "    for _ in tqdm(range(eval_episodes), desc=\"Evaluating policy\", unit=\"episode\"):\n",
    "        avg_reward += evaluate_episode(policy)\n",
    "\n",
    "    avg_reward /= eval_episodes\n",
    "\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"Evaluation over %d episodes: %f\" % (eval_episodes, avg_reward))\n",
    "    print(\"---------------------------------------\")\n",
    "    return avg_reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = ProstheticsEnvWithHistory(visualize=False, integrator_accuracy=CONFIG['env']['integrator_accuracy'])\n",
    "env_step_kwargs = {'project': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 19, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dim = env.observation_space.shape[0]\n",
    "env.reset(**env_step_kwargs)\n",
    "state_dim = prepare_model_observation(env).shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = int(env.action_space.high[0])\n",
    "state_dim, action_dim, max_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = TD3(state_dim, action_dim, max_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from checkpoints/checkpoint_TD3*\n",
      "Failed to load existing model checkpoint — this is normal if you're trying to train a new model (not from a checkpoint).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(f'Loading checkpoint from {CHECKPOINTS_DIR/CONFIG[\"training\"][\"checkpoint_save_load_prefix\"]}*')\n",
    "    policy.load(CHECKPOINTS_DIR, CONFIG[\"training\"][\"checkpoint_save_load_prefix\"])\n",
    "except:\n",
    "    print(\"Failed to load existing model checkpoint — this is normal if you're trying to train a new model (not from a checkpoint).\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%timeit -n1 -r1\n",
    "# evaluations = [evaluate_policy(policy)]\n",
    "evaluations = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 saved episode timesteps.\n"
     ]
    }
   ],
   "source": [
    "# Load saved episodes from disk\n",
    "if os.path.exists(CONFIG['training']['episode_save_load_file']):\n",
    "    df_saved_episodes = pd.read_hdf(CONFIG['training']['episode_save_load_file'])\n",
    "else:\n",
    "    df_saved_episodes = pd.DataFrame(columns=env.history().columns)\n",
    "    \n",
    "print(f'Loaded {len(df_saved_episodes)} saved episode timesteps.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.0, -1, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize based on loaded episode history\n",
    "total_timesteps = len(df_saved_episodes)\n",
    "timesteps_since_eval = len(df_saved_episodes) % CONFIG['training']['eval_freq']\n",
    "episode_num = len(df_saved_episodes['episode_uuid'].unique()) - 1\n",
    "done = True\n",
    "episode_timesteps = df_saved_episodes['i_step'].iloc[-1] if total_timesteps > 0 else 0\n",
    "total_timesteps, timesteps_since_eval, episode_num, episode_timesteps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.13876400884778411 0.06273868911010606\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20150269795789016).\n",
      "Total T: 11 Episode Num: 0 Episode T: 11 Reward: 35.43506634798316\n",
      "-0.15462359669252684 0.059591450039721064\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2142150467322479).\n",
      "Total T: 27 Episode Num: 1 Episode T: 16 Reward: 34.57707824491329\n",
      "-0.1503674592430194 0.055268684997500296\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20563614424051968).\n",
      "Total T: 47 Episode Num: 2 Episode T: 20 Reward: 31.886474990890747\n",
      "-0.13486544085689717 0.06552271343739556\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20038815429429274).\n",
      "Total T: 57 Episode Num: 3 Episode T: 10 Reward: 35.54114907912499\n",
      "-0.14341715950241202 0.07355862041109143\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21697577991350345).\n",
      "Total T: 69 Episode Num: 4 Episode T: 12 Reward: 41.12720894055058\n",
      "-0.14645787204372127 0.062358306584047694\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20881617862776897).\n",
      "Total T: 84 Episode Num: 5 Episode T: 15 Reward: 35.54230015300031\n",
      "-0.14179526552232308 0.06157393568175237\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20336920120407545).\n",
      "Total T: 102 Episode Num: 6 Episode T: 18 Reward: 35.31255645996487\n",
      "-0.14673112442385577 0.06477712499155185\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21150824941540763).\n",
      "Total T: 116 Episode Num: 7 Episode T: 14 Reward: 36.73143870432022\n",
      "-0.15095139415863046 0.07200998789097648\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.22296138204960694).\n",
      "Total T: 127 Episode Num: 8 Episode T: 11 Reward: 40.38434961137376\n",
      "-0.1607693663751642 0.04592152208738915\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20669088846255335).\n",
      "Total T: 146 Episode Num: 9 Episode T: 19 Reward: 26.293578248849023\n",
      "-0.14676914340857022 0.06351185418427589\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21028099759284613).\n",
      "Total T: 160 Episode Num: 10 Episode T: 14 Reward: 35.81004647095627\n",
      "-0.15820545030749747 0.054686212002078176\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21289166230957565).\n",
      "Total T: 175 Episode Num: 11 Episode T: 15 Reward: 30.92612425026941\n",
      "-0.1527574512234124 0.060567637745422793\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21332508896883517).\n",
      "Total T: 192 Episode Num: 12 Episode T: 17 Reward: 35.25920312168425\n",
      "-0.1337510141537032 0.06707237841762524\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20082339257132842).\n",
      "Total T: 202 Episode Num: 13 Episode T: 10 Reward: 36.902189573452375\n",
      "-0.1580231406969101 0.059657877698438\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2176810183953481).\n",
      "Total T: 221 Episode Num: 14 Episode T: 19 Reward: 34.95069546414597\n",
      "-0.1510188872130349 0.05772208657736353\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20874097379039844).\n",
      "Total T: 238 Episode Num: 15 Episode T: 17 Reward: 33.28440275412247\n",
      "-0.14136292089901709 0.06010940647168202\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2014723273706991).\n",
      "Total T: 253 Episode Num: 16 Episode T: 15 Reward: 34.588587440553155\n",
      "-0.16542840535203795 0.03923217691624033\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20466058226827827).\n",
      "Total T: 276 Episode Num: 17 Episode T: 23 Reward: 21.5595965837192\n",
      "-0.14857279181523084 0.058424854792789985\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20699764660802084).\n",
      "Total T: 290 Episode Num: 18 Episode T: 14 Reward: 33.870223914914355\n",
      "-0.14366937059084212 0.05977079343626616\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20344016402710827).\n",
      "Total T: 305 Episode Num: 19 Episode T: 15 Reward: 35.078770423109134\n",
      "-0.15296770926522746 0.07368147729789844\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.22664918656312588).\n",
      "Total T: 319 Episode Num: 20 Episode T: 14 Reward: 40.24010085991934\n",
      "-0.16209177754579535 0.05342358539012044\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21551536293591578).\n",
      "Total T: 338 Episode Num: 21 Episode T: 19 Reward: 30.035312361898082\n",
      "-0.1499649211945492 0.05221530147252631\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20218022266707553).\n",
      "Total T: 354 Episode Num: 22 Episode T: 16 Reward: 30.417727162997917\n",
      "-0.14101820064988052 0.06020791767865945\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20122611832853998).\n",
      "Total T: 366 Episode Num: 23 Episode T: 12 Reward: 33.533382428344\n",
      "-0.1426541021870345 0.05954873878903227\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20220284097606678).\n",
      "Total T: 379 Episode Num: 24 Episode T: 13 Reward: 34.36425296248891\n",
      "-0.16229088795058225 0.038843652022073766\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.201134539972656).\n",
      "Total T: 397 Episode Num: 25 Episode T: 18 Reward: 23.098807097554012\n",
      "-0.148588468516895 0.05881220085452068\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20740066937141569).\n",
      "Total T: 413 Episode Num: 26 Episode T: 16 Reward: 34.308549317091604\n",
      "-0.14575054046682817 0.05443376917858417\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20018430964541234).\n",
      "Total T: 427 Episode Num: 27 Episode T: 14 Reward: 28.59213948184557\n",
      "-0.13796352972344156 0.06655162565915294\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20451515538259452).\n",
      "Total T: 438 Episode Num: 28 Episode T: 11 Reward: 37.22543807006582\n",
      "-0.14757006362352948 0.06330214533528972\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2108722089588192).\n",
      "Total T: 452 Episode Num: 29 Episode T: 14 Reward: 35.66843317678524\n",
      "-0.17521937633441015 0.03559473343254481\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21081410976695497).\n",
      "Total T: 475 Episode Num: 30 Episode T: 23 Reward: 21.256212678606644\n",
      "-0.1547791347780793 0.05244829806343996\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20722743284151926).\n",
      "Total T: 492 Episode Num: 31 Episode T: 17 Reward: 28.802885357565998\n",
      "-0.14058653398275958 0.07177673250682377\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21236326648958337).\n",
      "Total T: 506 Episode Num: 32 Episode T: 14 Reward: 40.64189403761023\n",
      "-0.15691326916939366 0.0497447239235209\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20665799309291455).\n",
      "Total T: 532 Episode Num: 33 Episode T: 26 Reward: 26.733167946665645\n",
      "-0.15981848108857433 0.04164723214776176\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20146571323633608).\n",
      "Total T: 556 Episode Num: 34 Episode T: 24 Reward: 23.07451163751518\n",
      "-0.14523847569383505 0.06692650477750353\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21216498047133858).\n",
      "Total T: 567 Episode Num: 35 Episode T: 11 Reward: 37.65022839066227\n",
      "-0.1673899243148979 0.04238664118367409\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.209776565498572).\n",
      "Total T: 586 Episode Num: 36 Episode T: 19 Reward: 25.754410615340756\n",
      "-0.1555224088511554 0.05665760124030707\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21218001009146248).\n",
      "Total T: 603 Episode Num: 37 Episode T: 17 Reward: 32.67259989733654\n",
      "-0.1505208371481487 0.06479482531010894\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21531566245825765).\n",
      "Total T: 620 Episode Num: 38 Episode T: 17 Reward: 37.23831828459312\n",
      "-0.15136982388216622 0.06094229172527869\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2123121156074449).\n",
      "Total T: 634 Episode Num: 39 Episode T: 14 Reward: 35.3167621392163\n",
      "-0.15455577471030194 0.06394547874832476\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2185012534586267).\n",
      "Total T: 649 Episode Num: 40 Episode T: 15 Reward: 37.03365994690383\n",
      "-0.16120099073076832 0.04626406318130076\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2074650539120691).\n",
      "Total T: 668 Episode Num: 41 Episode T: 19 Reward: 27.11637639886032\n",
      "-0.1475137767559077 0.060057799308726414\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2075715760646341).\n",
      "Total T: 684 Episode Num: 42 Episode T: 16 Reward: 34.760581629550835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.19147309075965144 0.019800976817729323\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21127406757738076).\n",
      "Total T: 711 Episode Num: 43 Episode T: 27 Reward: 11.335725951884346\n",
      "-0.14019375239456092 0.06262545976276687\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2028192121573278).\n",
      "Total T: 724 Episode Num: 44 Episode T: 13 Reward: 35.24279424516603\n",
      "-0.14415453227333672 0.07207441002376652\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21622894229710324).\n",
      "Total T: 739 Episode Num: 45 Episode T: 15 Reward: 40.65239371405581\n",
      "-0.1448257042497914 0.0646612081391531\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2094869123889445).\n",
      "Total T: 752 Episode Num: 46 Episode T: 13 Reward: 36.95092482782803\n",
      "-0.15432121187606407 0.055598748394860294\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20991996027092436).\n",
      "Total T: 767 Episode Num: 47 Episode T: 15 Reward: 32.62538085996184\n",
      "-0.15128978390600872 0.058659914033660276\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.209949697939669).\n",
      "Total T: 789 Episode Num: 48 Episode T: 22 Reward: 34.300858112995\n",
      "-0.16361151194437007 0.0411876255309438\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20479913747531386).\n",
      "Total T: 813 Episode Num: 49 Episode T: 24 Reward: 22.848789283988552\n",
      "-0.1440857281794104 0.06649938531017183\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21058511348958223).\n",
      "Total T: 824 Episode Num: 50 Episode T: 11 Reward: 37.29362011316968\n",
      "-0.14252034668473768 0.059733125595512276\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20225347228024995).\n",
      "Total T: 841 Episode Num: 51 Episode T: 17 Reward: 32.4518947015883\n",
      "-0.15613840067920354 0.06747228257447017\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.22361068325367373).\n",
      "Total T: 855 Episode Num: 52 Episode T: 14 Reward: 38.25546307834036\n",
      "-0.13905671504746167 0.06806206085116147\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20711877589862315).\n",
      "Total T: 868 Episode Num: 53 Episode T: 13 Reward: 38.919852730121015\n",
      "-0.14274680089924388 0.07313824971853107\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21588505061777497).\n",
      "Total T: 879 Episode Num: 54 Episode T: 11 Reward: 40.53263483456123\n",
      "-0.1467991928318092 0.05928140689926901\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2060805997310782).\n",
      "Total T: 893 Episode Num: 55 Episode T: 14 Reward: 34.622766889491054\n",
      "-0.14518175015796142 0.05807288502147533\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20325463517943676).\n",
      "Total T: 909 Episode Num: 56 Episode T: 16 Reward: 32.106085321484855\n",
      "-0.14579780494245198 0.05933080462994353\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2051286095723955).\n",
      "Total T: 923 Episode Num: 57 Episode T: 14 Reward: 34.167324515222745\n",
      "-0.15499514823784066 0.04790590498277305\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20290105322061372).\n",
      "Total T: 944 Episode Num: 58 Episode T: 21 Reward: 27.188058589414737\n",
      "-0.14077944337588208 0.0612348677867867\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20201431116266877).\n",
      "Total T: 956 Episode Num: 59 Episode T: 12 Reward: 35.14661323427933\n",
      "-0.13872398788099766 0.06638531003934844\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2051092979203461).\n",
      "Total T: 968 Episode Num: 60 Episode T: 12 Reward: 37.76542351448066\n",
      "-0.15133567422804467 0.05830799657293839\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20964367080098306).\n",
      "Total T: 982 Episode Num: 61 Episode T: 14 Reward: 33.62737942821951\n",
      "-0.16128229032326113 0.047432140797005556\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2087144311202667).\n",
      "Total T: 1004 Episode Num: 62 Episode T: 22 Reward: 28.260627953170804\n",
      "-0.14403912043293265 0.06627870092082751\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21031782135376015).\n",
      "Total T: 1015 Episode Num: 63 Episode T: 11 Reward: 37.34955567196989\n",
      "-0.15559548256192007 0.05355298900602077\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20914847156794084).\n",
      "Total T: 1033 Episode Num: 64 Episode T: 18 Reward: 31.057386497368917\n",
      "-0.14190744375623185 0.0631644871289959\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20507193088522774).\n",
      "Total T: 1049 Episode Num: 65 Episode T: 16 Reward: 36.54947573321214\n",
      "-0.16824402699117905 0.04721852296223514\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21546254995341418).\n",
      "Total T: 1069 Episode Num: 66 Episode T: 20 Reward: 27.887653943274124\n",
      "-0.14425403086065353 0.07540304164374441\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21965707250439792).\n",
      "Total T: 1079 Episode Num: 67 Episode T: 10 Reward: 41.29184859664997\n",
      "-0.14486012709839036 0.05957296373962307\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20443309083801342).\n",
      "Total T: 1092 Episode Num: 68 Episode T: 13 Reward: 34.58933003095237\n",
      "-0.1489834378888254 0.06370145652024434\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21268489440906974).\n",
      "Total T: 1104 Episode Num: 69 Episode T: 12 Reward: 36.40434210397795\n",
      "-0.1421326031553568 0.07175842401696302\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21389102717231984).\n",
      "Total T: 1115 Episode Num: 70 Episode T: 11 Reward: 40.05448084106265\n",
      "-0.16535313484563383 0.04996034903857553\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21531348388420934).\n",
      "Total T: 1136 Episode Num: 71 Episode T: 21 Reward: 27.682412937302743\n",
      "-0.15341743630860533 0.06468510546821439\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2181025417768197).\n",
      "Total T: 1151 Episode Num: 72 Episode T: 15 Reward: 35.69957940949439\n",
      "-0.13811558734444096 0.07204613646647692\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21016172381091788).\n",
      "Total T: 1161 Episode Num: 73 Episode T: 10 Reward: 39.71563310321996\n",
      "-0.1536944551869157 0.05687459913902087\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2105690543259366).\n",
      "Total T: 1181 Episode Num: 74 Episode T: 20 Reward: 33.33684080187915\n",
      "-0.14190344740296218 0.05957293778889495\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20147638519185712).\n",
      "Total T: 1193 Episode Num: 75 Episode T: 12 Reward: 33.465981773559385\n",
      "-0.1791024999127734 0.02595067518950033\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20505317510227375).\n",
      "Total T: 1217 Episode Num: 76 Episode T: 24 Reward: 15.20618738905161\n",
      "-0.1504290654058385 0.07249720069932106\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.22292626610515956).\n",
      "Total T: 1229 Episode Num: 77 Episode T: 12 Reward: 39.9308974351587\n",
      "-0.15373035889051528 0.06022644081300814\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21395679970352344).\n",
      "Total T: 1242 Episode Num: 78 Episode T: 13 Reward: 34.72875514746037\n",
      "-0.14561975809627148 0.06385288665475809\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20947264475102956).\n",
      "Total T: 1253 Episode Num: 79 Episode T: 11 Reward: 35.985317821448\n",
      "-0.14127621924375333 0.07028340262767918\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2115596218714325).\n",
      "Total T: 1266 Episode Num: 80 Episode T: 13 Reward: 39.128021287337646\n",
      "-0.1411394451193029 0.061661359723347346\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20280080484265026).\n",
      "Total T: 1278 Episode Num: 81 Episode T: 12 Reward: 34.79153790741862\n",
      "-0.14922217144731667 0.05949336119120099\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20871553263851766).\n",
      "Total T: 1293 Episode Num: 82 Episode T: 15 Reward: 34.32703971751837\n",
      "-0.14611556040632678 0.07276600798430362\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2188815683906304).\n",
      "Total T: 1303 Episode Num: 83 Episode T: 10 Reward: 39.23823716686511\n",
      "-0.14578880153946083 0.07178266492724646\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21757146646670728).\n",
      "Total T: 1313 Episode Num: 84 Episode T: 10 Reward: 39.551099736237106\n",
      "-0.14278012928859182 0.06867586707192327\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2114559963605151).\n",
      "Total T: 1327 Episode Num: 85 Episode T: 14 Reward: 39.593726525427336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.13931820258087088 0.07217063066935563\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2114888332502265).\n",
      "Total T: 1339 Episode Num: 86 Episode T: 12 Reward: 40.553722333557694\n",
      "-0.1399440040539145 0.06885819220436878\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20880219625828328).\n",
      "Total T: 1350 Episode Num: 87 Episode T: 11 Reward: 38.10137982614998\n",
      "-0.14594495065143387 0.06896484878896438\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21490979944039823).\n",
      "Total T: 1361 Episode Num: 88 Episode T: 11 Reward: 38.480205618541525\n",
      "-0.1364743646336566 0.06412807718833341\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20060244182199).\n",
      "Total T: 1376 Episode Num: 89 Episode T: 15 Reward: 37.04592650260125\n",
      "-0.3603978993217228 -0.15803864313633492\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20235925618538786).\n",
      "Total T: 1426 Episode Num: 90 Episode T: 50 Reward: -105.03291642163438\n",
      "-0.15193153622342423 0.07018333882144359\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.22211487504486782).\n",
      "Total T: 1437 Episode Num: 91 Episode T: 11 Reward: 39.50533315486001\n",
      "-0.14165833553703794 0.06041063125538456\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2020689667924225).\n",
      "Total T: 1451 Episode Num: 92 Episode T: 14 Reward: 34.602865806600434\n",
      "-0.1461249788032919 0.07243505057199791\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2185600293752898).\n",
      "Total T: 1464 Episode Num: 93 Episode T: 13 Reward: 40.41188324134682\n",
      "-0.13933524949921794 0.06840855275620193\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20774380225541988).\n",
      "Total T: 1475 Episode Num: 94 Episode T: 11 Reward: 37.49820501335117\n",
      "-0.15393879893400975 0.05288593999907507\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2068247389330848).\n",
      "Total T: 1492 Episode Num: 95 Episode T: 17 Reward: 30.988866754103277\n",
      "-0.14858725875642398 0.057686662784767015\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.206273921541191).\n",
      "Total T: 1507 Episode Num: 96 Episode T: 15 Reward: 33.31048911949297\n",
      "-0.14074796314531438 0.06706465894424427\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20781262208955864).\n",
      "Total T: 1517 Episode Num: 97 Episode T: 10 Reward: 37.397644976776355\n",
      "-0.14991379754254558 0.056560223182863946\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20647402072540952).\n",
      "Total T: 1534 Episode Num: 98 Episode T: 17 Reward: 33.0638040220544\n",
      "-0.15173297262163166 0.060564336217076284\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21229730883870795).\n",
      "Total T: 1547 Episode Num: 99 Episode T: 13 Reward: 34.79769765968654\n",
      "-0.14150586035603735 0.06272141293524443\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20422727329128176).\n",
      "Total T: 1561 Episode Num: 100 Episode T: 14 Reward: 34.33675288842706\n",
      "-0.14453870383762843 0.062315342656651784\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2068540464942802).\n",
      "Total T: 1574 Episode Num: 101 Episode T: 13 Reward: 33.63998946676226\n",
      "-0.15126673738949467 0.054489238790621265\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20575597618011593).\n",
      "Total T: 1591 Episode Num: 102 Episode T: 17 Reward: 32.27918549404346\n",
      "-0.1404849659875795 0.07507454549555241\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2155595114831319).\n",
      "Total T: 1603 Episode Num: 103 Episode T: 12 Reward: 41.402689716543776\n",
      "-0.15529821041459568 0.05807599423233906\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21337420464693474).\n",
      "Total T: 1625 Episode Num: 104 Episode T: 22 Reward: 33.549335642310595\n",
      "-0.1571720101724038 0.06077833596326213\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2179503461356659).\n",
      "Total T: 1639 Episode Num: 105 Episode T: 14 Reward: 34.91011675629396\n",
      "-0.14520041740907144 0.06207443674598743\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20727485415505886).\n",
      "Total T: 1653 Episode Num: 106 Episode T: 14 Reward: 35.323224177284075\n",
      "-0.16829855954001977 0.03353006360179088\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20182862314181066).\n",
      "Total T: 1676 Episode Num: 107 Episode T: 23 Reward: 18.550023145867932\n",
      "-0.13402890730893954 0.06666986452864723\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20069877183758678).\n",
      "Total T: 1686 Episode Num: 108 Episode T: 10 Reward: 36.93996787527158\n",
      "-0.14565712818153398 0.061067853504111015\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.206724981685645).\n",
      "Total T: 1700 Episode Num: 109 Episode T: 14 Reward: 34.92020898491349\n",
      "-0.13846244097870664 0.0615453162889805\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20000775726768713).\n",
      "Total T: 1711 Episode Num: 110 Episode T: 11 Reward: 34.890007779731214\n",
      "-0.16492369573873145 0.03976106307694828\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2046847588156797).\n",
      "Total T: 1729 Episode Num: 111 Episode T: 18 Reward: 22.052650480739327\n",
      "-0.15943942742282025 0.049155225684207715\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20859465310702796).\n",
      "Total T: 1750 Episode Num: 112 Episode T: 21 Reward: 28.625862025438842\n",
      "-0.13327593900300796 0.06937185280351903\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20264779180652698).\n",
      "Total T: 1762 Episode Num: 113 Episode T: 12 Reward: 38.98963428931332\n",
      "-0.1513509699483797 0.05244639191947229\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.203797361867852).\n",
      "Total T: 1782 Episode Num: 114 Episode T: 20 Reward: 29.264258800489046\n",
      "-0.1458392659315897 0.05452451289169297\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20036377882328266).\n",
      "Total T: 1799 Episode Num: 115 Episode T: 17 Reward: 31.405760178770993\n",
      "-0.14264799842551473 0.06318680880345522\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20583480722896996).\n",
      "Total T: 1814 Episode Num: 116 Episode T: 15 Reward: 36.515698383097366\n",
      "-0.1578402714466483 0.054636491683763645\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21247676313041194).\n",
      "Total T: 1832 Episode Num: 117 Episode T: 18 Reward: 32.18455742785321\n",
      "-0.1387626499542376 0.06573419261611008\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20449684257034767).\n",
      "Total T: 1844 Episode Num: 118 Episode T: 12 Reward: 36.78295296493331\n",
      "-0.14772923722117226 0.06520530557748083\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2129345427986531).\n",
      "Total T: 1858 Episode Num: 119 Episode T: 14 Reward: 35.93157624629413\n",
      "-0.13987776424860343 0.06458492245544115\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20446268670404458).\n",
      "Total T: 1869 Episode Num: 120 Episode T: 11 Reward: 36.28633131693928\n",
      "-0.1623265345110547 0.0460143912435678\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20834092575462249).\n",
      "Total T: 1890 Episode Num: 121 Episode T: 21 Reward: 25.301667730653875\n",
      "-0.14668478927774825 0.06202864202577067\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20871343130351894).\n",
      "Total T: 1905 Episode Num: 122 Episode T: 15 Reward: 35.64998084078945\n",
      "-0.1451022291591735 0.06206254660680863\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20716477576598213).\n",
      "Total T: 1919 Episode Num: 123 Episode T: 14 Reward: 34.99981373669541\n",
      "-0.15115476889788554 0.06384491525631723\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21499968415420279).\n",
      "Total T: 1933 Episode Num: 124 Episode T: 14 Reward: 36.6004547774693\n",
      "-0.1480256825557018 0.0648123494228953\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2128380319785971).\n",
      "Total T: 1948 Episode Num: 125 Episode T: 15 Reward: 36.57474444553029\n",
      "-0.14913582734532083 0.06750875058438484\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21664457792970565).\n",
      "Total T: 1961 Episode Num: 126 Episode T: 13 Reward: 38.36768231460143\n",
      "-0.14923559688807111 0.05337610924899132\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20261170613706242).\n",
      "Total T: 1978 Episode Num: 127 Episode T: 17 Reward: 31.225890485856176\n",
      "-0.16109280930264402 0.05242720837702304\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21352001767966705).\n",
      "Total T: 1998 Episode Num: 128 Episode T: 20 Reward: 30.679156839936347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1437607126500197 0.06282431160971982\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2065850242597395).\n",
      "Total T: 2017 Episode Num: 129 Episode T: 19 Reward: 36.56007384574263\n",
      "-0.1436047925697776 0.06490939176405872\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2085141843338363).\n",
      "Total T: 2030 Episode Num: 130 Episode T: 13 Reward: 36.97525512259188\n",
      "-0.14801218627841506 0.06867130991908822\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21668349619750327).\n",
      "Total T: 2042 Episode Num: 131 Episode T: 12 Reward: 38.098395295080394\n",
      "-0.14485072846601943 0.06678800140191749\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21163872986793691).\n",
      "Total T: 2054 Episode Num: 132 Episode T: 12 Reward: 37.43504005044569\n",
      "-0.14141464401918102 0.06378561057443732\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20520025459361835).\n",
      "Total T: 2067 Episode Num: 133 Episode T: 13 Reward: 36.362276331703356\n",
      "-0.1467449434211912 0.060306946783536645\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20705189020472786).\n",
      "Total T: 2081 Episode Num: 134 Episode T: 14 Reward: 34.19985053485032\n",
      "-0.16187486183924885 0.04921509957304685\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2110899614122957).\n",
      "Total T: 2100 Episode Num: 135 Episode T: 19 Reward: 27.731166728525928\n",
      "-0.143327282426928 0.07592998486043907\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21925726728736705).\n",
      "Total T: 2109 Episode Num: 136 Episode T: 9 Reward: 40.12288664452107\n",
      "-0.14508558124677895 0.06784511433932147\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21293069558610042).\n",
      "Total T: 2120 Episode Num: 137 Episode T: 11 Reward: 37.8091195877168\n",
      "-0.1442384114308932 0.06468807232702635\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20892648375791956).\n",
      "Total T: 2133 Episode Num: 138 Episode T: 13 Reward: 36.88483059494723\n",
      "-0.1530577601156655 0.06097354499781718\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21403130511348267).\n",
      "Total T: 2151 Episode Num: 139 Episode T: 18 Reward: 34.901548230397886\n",
      "-0.1596991613706477 0.04868883663986997\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2083879980105177).\n",
      "Total T: 2171 Episode Num: 140 Episode T: 20 Reward: 29.30104188424882\n",
      "-0.1434062621200331 0.06214945383486181\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2055557159548949).\n",
      "Total T: 2185 Episode Num: 141 Episode T: 14 Reward: 35.72726920001472\n",
      "-0.15503762589505996 0.05026109129820158\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20529871719326154).\n",
      "Total T: 2205 Episode Num: 142 Episode T: 20 Reward: 29.366320684629404\n",
      "-0.14359184354976373 0.06070091951339725\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20429276306316096).\n",
      "Total T: 2218 Episode Num: 143 Episode T: 13 Reward: 34.80712293671208\n",
      "-0.139588518211468 0.06649973112173392\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2060882493332019).\n",
      "Total T: 2229 Episode Num: 144 Episode T: 11 Reward: 36.73474703153137\n",
      "-0.1472946910357855 0.06559096645185651\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.212885657487642).\n",
      "Total T: 2241 Episode Num: 145 Episode T: 12 Reward: 36.51821023531226\n",
      "-0.19762467495894526 0.011766961107937334\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2093916360668826).\n",
      "Total T: 2272 Episode Num: 146 Episode T: 31 Reward: 5.258143199834029\n",
      "-0.16804256189979155 0.03800292960217417\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20604549150196572).\n",
      "Total T: 2294 Episode Num: 147 Episode T: 22 Reward: 22.367982397567673\n",
      "-0.13693158404204792 0.06841887914463683\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20535046318668476).\n",
      "Total T: 2310 Episode Num: 148 Episode T: 16 Reward: 39.37295880733855\n",
      "-0.1308055803606923 0.07199276967929868\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20279835003999097).\n",
      "Total T: 2325 Episode Num: 149 Episode T: 15 Reward: 39.92233797076391\n",
      "-0.15211282708152246 0.06061855647323661\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21273138355475907).\n",
      "Total T: 2346 Episode Num: 150 Episode T: 21 Reward: 34.64424045995251\n",
      "-0.17294316585008646 0.03113071373782753\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20407387958791398).\n",
      "Total T: 2366 Episode Num: 151 Episode T: 20 Reward: 18.351867497613686\n",
      "-0.14934203036440538 0.0679274434134959\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2172694737779013).\n",
      "Total T: 2377 Episode Num: 152 Episode T: 11 Reward: 38.593656543028374\n",
      "-0.16033775255423693 0.04433752115779681\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20467527371203376).\n",
      "Total T: 2402 Episode Num: 153 Episode T: 25 Reward: 26.251811351551844\n",
      "-0.1453532149785735 0.07204695117384453\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21740016615241803).\n",
      "Total T: 2413 Episode Num: 154 Episode T: 11 Reward: 39.88573811064056\n",
      "-0.16725841789323728 0.060318391915707724\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.227576809808945).\n",
      "Total T: 2432 Episode Num: 155 Episode T: 19 Reward: 35.29326677401245\n",
      "-0.13735895516418317 0.06303313259438492\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2003920877585681).\n",
      "Total T: 2444 Episode Num: 156 Episode T: 12 Reward: 35.81563651248396\n",
      "-0.13273221356246173 0.0682431605880989\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20097537415056063).\n",
      "Total T: 2457 Episode Num: 157 Episode T: 13 Reward: 39.167113057437255\n",
      "-0.1576336320473386 0.054762887681953164\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21239651972929177).\n",
      "Total T: 2473 Episode Num: 158 Episode T: 16 Reward: 31.862658057872377\n",
      "-0.17974012388368976 0.02284220554475209\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20258232942844184).\n",
      "Total T: 2500 Episode Num: 159 Episode T: 27 Reward: 11.837942723879834\n",
      "-0.14711590787301584 0.054735462681710555\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2018513705547264).\n",
      "Total T: 2517 Episode Num: 160 Episode T: 17 Reward: 31.56634080562184\n",
      "-0.14914666298039 0.06319520617062956\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21234186915101955).\n",
      "Total T: 2530 Episode Num: 161 Episode T: 13 Reward: 35.803681256908575\n",
      "-0.14019476552765547 0.06482270114467387\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20501746667232934).\n",
      "Total T: 2542 Episode Num: 162 Episode T: 12 Reward: 36.758296077924264\n",
      "-0.14529387352265316 0.06432497526402615\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2096188487866793).\n",
      "Total T: 2555 Episode Num: 163 Episode T: 13 Reward: 36.82931608089257\n",
      "-0.13941547223972983 0.06621509001088957\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2056305622506194).\n",
      "Total T: 2568 Episode Num: 164 Episode T: 13 Reward: 37.89433283043755\n",
      "-0.14532092130593957 0.0587278918693439\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20404881317528348).\n",
      "Total T: 2580 Episode Num: 165 Episode T: 12 Reward: 32.688216526241874\n",
      "-0.1403020878007205 0.06253251625474399\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2028346040554645).\n",
      "Total T: 2593 Episode Num: 166 Episode T: 13 Reward: 35.92950388974445\n",
      "-0.1354719557742048 0.0712379759002754\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2067099316744802).\n",
      "Total T: 2605 Episode Num: 167 Episode T: 12 Reward: 39.84944364460283\n",
      "-0.18177133102268384 0.02141354372724827\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2031848747499321).\n",
      "Total T: 2633 Episode Num: 168 Episode T: 28 Reward: 12.021436271493739\n",
      "-0.13989205123784737 0.06771968739053337\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20761173862838073).\n",
      "Total T: 2644 Episode Num: 169 Episode T: 11 Reward: 37.48204135279094\n",
      "-0.13794322150604515 0.06876233570988947\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20670555721593464).\n",
      "Total T: 2655 Episode Num: 170 Episode T: 11 Reward: 38.059257728653485\n",
      "-0.145696821653511 0.07370000022247913\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21939682187599013).\n",
      "Total T: 2667 Episode Num: 171 Episode T: 12 Reward: 40.79173793053894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.14773710897261974 0.058067418161572834\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20580452713419256).\n",
      "Total T: 2681 Episode Num: 172 Episode T: 14 Reward: 33.20906181432305\n",
      "-0.1714146298671788 0.039032673165753345\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21044730303293216).\n",
      "Total T: 2704 Episode Num: 173 Episode T: 23 Reward: 23.140109676331498\n",
      "-0.14474666311548878 0.06967614074030215\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21442280385579093).\n",
      "Total T: 2716 Episode Num: 174 Episode T: 12 Reward: 39.403282680947214\n",
      "-0.1536002113615742 0.04887021858197665\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20247042994355086).\n",
      "Total T: 2733 Episode Num: 175 Episode T: 17 Reward: 28.398601796289583\n",
      "-0.14803952769258233 0.06614584986258834\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21418537755517067).\n",
      "Total T: 2747 Episode Num: 176 Episode T: 14 Reward: 37.38121069572466\n",
      "-0.14168753419589664 0.06366606963343692\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20535360382933354).\n",
      "Total T: 2758 Episode Num: 177 Episode T: 11 Reward: 35.52061814989059\n",
      "-0.14957385290290162 0.06639505553756728\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2159689084404689).\n",
      "Total T: 2772 Episode Num: 178 Episode T: 14 Reward: 38.15514134281125\n",
      "-0.136131086221407 0.06422662037184913\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20035770659325614).\n",
      "Total T: 2783 Episode Num: 179 Episode T: 11 Reward: 36.06072108040406\n",
      "-0.14490359895517094 0.05804216097918325\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20294575993435418).\n",
      "Total T: 2798 Episode Num: 180 Episode T: 15 Reward: 33.6487947494683\n",
      "-0.14106910028331154 0.061679439702516554\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2027485399858281).\n",
      "Total T: 2810 Episode Num: 181 Episode T: 12 Reward: 34.6955319539011\n",
      "-0.14836399486749677 0.05636085341743343\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2047248482849302).\n",
      "Total T: 2825 Episode Num: 182 Episode T: 15 Reward: 32.03569600717427\n",
      "-0.14449620258951273 0.06470655470542006\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2092027572949328).\n",
      "Total T: 2842 Episode Num: 183 Episode T: 17 Reward: 37.394593023091524\n",
      "-0.143687472084388 0.0710158978538822\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21470336993827022).\n",
      "Total T: 2853 Episode Num: 184 Episode T: 11 Reward: 39.01066852706528\n",
      "-0.17420266805903234 0.04829629950274632\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.22249896756177867).\n",
      "Total T: 2875 Episode Num: 185 Episode T: 22 Reward: 26.752705779595328\n",
      "-0.14022175378469742 0.06127125708618431\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20149301087088173).\n",
      "Total T: 2889 Episode Num: 186 Episode T: 14 Reward: 35.28099097656596\n",
      "-0.15098083096948445 0.05570399890266799\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20668482987215242).\n",
      "Total T: 2908 Episode Num: 187 Episode T: 19 Reward: 32.37740045490476\n",
      "-0.15907656531155387 0.05020004015074271\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2092766054622966).\n",
      "Total T: 2926 Episode Num: 188 Episode T: 18 Reward: 29.535091574041513\n",
      "-0.15028240230631876 0.05475365453292357\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20503605683924234).\n",
      "Total T: 2947 Episode Num: 189 Episode T: 21 Reward: 31.72753782465076\n",
      "-0.1436104436062937 0.058877159466903625\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2024876030731973).\n",
      "Total T: 2961 Episode Num: 190 Episode T: 14 Reward: 33.556394208536226\n",
      "-0.14001087287394992 0.06701012589102484\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20702099876497476).\n",
      "Total T: 2974 Episode Num: 191 Episode T: 13 Reward: 38.18439359020707\n",
      "-0.14380657568771874 0.06570765935275388\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20951423504047262).\n",
      "Total T: 2986 Episode Num: 192 Episode T: 12 Reward: 36.47686761058238\n",
      "-0.13402765105772207 0.07571848628945484\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2097461373471769).\n",
      "Total T: 2995 Episode Num: 193 Episode T: 9 Reward: 40.00747352410701\n",
      "-0.14053810389739793 0.06311433400528234\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20365243790268028).\n",
      "Total T: 3013 Episode Num: 194 Episode T: 18 Reward: 37.08394972075071\n",
      "-0.14504153348373316 0.06681464661736035\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21185618010109353).\n",
      "Total T: 3027 Episode Num: 195 Episode T: 14 Reward: 37.26551171357224\n",
      "-0.14477446902216923 0.05607930862469991\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20085377764686912).\n",
      "Total T: 3043 Episode Num: 196 Episode T: 16 Reward: 32.618970422050154\n",
      "-0.13733558828595083 0.0636373175539192\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20097290583987004).\n",
      "Total T: 3053 Episode Num: 197 Episode T: 10 Reward: 35.33479166015222\n",
      "-0.14077527502919895 0.06499106700595954\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20576634203515848).\n",
      "Total T: 3064 Episode Num: 198 Episode T: 11 Reward: 36.16995151779312\n",
      "-0.14199858720251085 0.05815140105106196\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.2001499882535728).\n",
      "Total T: 3084 Episode Num: 199 Episode T: 20 Reward: 33.43418537323376\n",
      "-0.16091948798257993 0.051088101853237075\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.21200758983581702).\n",
      "Total T: 3105 Episode Num: 200 Episode T: 21 Reward: 28.206592199871853\n",
      "-0.14226343550144932 0.0635350028287912\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20579843833024053).\n",
      "Total T: 3118 Episode Num: 201 Episode T: 13 Reward: 35.69016199018333\n",
      "-0.14175173880364023 0.06444042369052252\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20619216249416275).\n",
      "Total T: 3130 Episode Num: 202 Episode T: 12 Reward: 36.83214178556754\n",
      "-0.14687799090295456 0.05896210481430829\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20584009571726286).\n",
      "Total T: 3143 Episode Num: 203 Episode T: 13 Reward: 34.07751001378786\n",
      "-0.15084688158148005 0.055562823385163974\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20640970496664401).\n",
      "Total T: 3158 Episode Num: 204 Episode T: 15 Reward: 31.80804156354003\n"
     ]
    }
   ],
   "source": [
    "while total_timesteps < CONFIG['training']['max_timesteps']:\n",
    "    if done: \n",
    "        if total_timesteps >= CONFIG['training']['start_timesteps']: \n",
    "            df_env_history = pd.concat([df_saved_episodes, env.history()], ignore_index=True, copy=False)\n",
    "            history_sampler = EnvHistorySampler(\n",
    "                df_env_history,\n",
    "                env_obs_history_to_model_obs_fn=env_obs_history_to_model_obs, \n",
    "                env_obs_custom_reward_fn=lambda obs: sum(env_obs_to_custom_reward(obs).values()),\n",
    "                env_obs_custom_done_fn=should_abort_episode,\n",
    "            )\n",
    "            if CONFIG['model']['architecture'] == \"TD3\":\n",
    "                policy.train(\n",
    "                    history_sampler,#replay_buffer, \n",
    "                    episode_timesteps, \n",
    "                    CONFIG['training']['batch_size'], \n",
    "                    CONFIG['training']['discount'], \n",
    "                    CONFIG['training']['tau'], \n",
    "                    CONFIG['training']['policy_noise'], \n",
    "                    CONFIG['training']['noise_clip'], \n",
    "                    CONFIG['training']['policy_freq'],\n",
    "                )\n",
    "            else: \n",
    "                policy.train(\n",
    "                    history_sampler,#replay_buffer, \n",
    "                    episode_timesteps, \n",
    "                    CONFIG['training']['batch_size'], \n",
    "                    CONFIG['training']['discount'], \n",
    "                    CONFIG['training']['tau']\n",
    "                )\n",
    "        \n",
    "            # Evaluate policy, Checkpoint policy, Checkpoint history\n",
    "            if timesteps_since_eval >= CONFIG['training']['eval_freq']:\n",
    "                # Reset evaluation counter\n",
    "                timesteps_since_eval %= CONFIG['training']['eval_freq']\n",
    "                # Evaluate policy\n",
    "                evaluations.append(evaluate_policy(policy))\n",
    "                # Checkpoint policy\n",
    "                policy.save(CHECKPOINTS_DIR, f'{CONFIG[\"training\"][\"checkpoint_save_load_prefix\"]}_episode{episode_num}_eval{evaluations[-1]:.1f}')\n",
    "                policy.save(CHECKPOINTS_DIR, CONFIG[\"training\"][\"checkpoint_save_load_prefix\"])\n",
    "                # Checkpoint history\n",
    "                pd.concat([df_saved_episodes, env.history()], ignore_index=True, copy=False).to_hdf(CONFIG['training']['episode_save_load_file'], key='df')\n",
    "                # TODO Log evaluations, etc.\n",
    "        \n",
    "        # Reset environment\n",
    "        obs = env.reset(**env_step_kwargs)\n",
    "        reset_frameskip(CONFIG['training']['frameskip'])\n",
    "#         obs_dict = env.get_state_desc()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        episode_timesteps = 0\n",
    "        episode_num += 1 \n",
    "    \n",
    "    # Select action randomly or according to policy\n",
    "    if total_timesteps < CONFIG['training']['start_timesteps']:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = policy.select_action(prepare_model_observation(env))\n",
    "        if CONFIG['training']['expl_noise'] != 0: \n",
    "            action = (action + np.random.normal(0, CONFIG['training']['expl_noise'], size=env.action_space.shape[0])).clip(env.action_space.low, env.action_space.high)\n",
    "\n",
    "    # Perform action\n",
    "    action = prepare_env_action(action)\n",
    "    obs, reward, done, _ = env.step(action, **env_step_kwargs)\n",
    "#     new_obs_dict = env.get_state_desc()\n",
    "\n",
    "    if not done:\n",
    "        done = should_abort_episode(env.get_state_desc(), verbose=True)\n",
    "    done_bool = 0 if episode_timesteps + 1 == CONFIG['training']['max_episode_steps'] else float(done)\n",
    "\n",
    "    # custom_rewards = compute_rewards(new_obs_dict)\n",
    "    episode_reward += reward #+ sum(custom_rewards.values())\n",
    "\n",
    "    # Store data in replay buffer\n",
    "#     replay_buffer.add((obs_dict, new_obs_dict, action, reward, done_bool, episode_num))\n",
    "\n",
    "#     obs = new_obs\n",
    "#     obs_dict = new_obs_dict\n",
    "\n",
    "    episode_timesteps += 1\n",
    "    total_timesteps += 1\n",
    "    timesteps_since_eval += 1\n",
    "    \n",
    "    if done:\n",
    "        print(f\"Total T: {total_timesteps} Episode Num: {episode_num} Episode T: {episode_timesteps} Reward: {episode_reward}\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.history(current_episode_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prosthetics",
   "language": "python",
   "name": "prosthetics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
