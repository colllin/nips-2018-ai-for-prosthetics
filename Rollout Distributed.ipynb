{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from models.td3 import TD3\n",
    "# from osim.env import ProstheticsEnv\n",
    "from environment.prosthetics_env_with_history import ProstheticsEnvWithHistory\n",
    "from environment.observations import prepare_model_observation\n",
    "from environment.actions import prepare_env_action, reset_frameskip\n",
    "from environment.rewards import env_obs_to_custom_reward\n",
    "from distributed.database import persist_timesteps, persist_event\n",
    "from distributed.s3_checkpoints import load_s3_model_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"env\": {\n",
      "        \"integrator_accuracy\": 0.002\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"architecture\": \"TD3\"\n",
      "    },\n",
      "    \"rollout\": {\n",
      "        \"#\": \"Frameskip will be applied for random durations between 0 and `frameskip` timesteps.\",\n",
      "        \"max_episode_steps\": 600,\n",
      "        \"expl_noise\": 0.25,\n",
      "        \"frameskip\": 5\n",
      "    },\n",
      "    \"distributed\": {\n",
      "        \"policy_weights_dir_s3\": \"s3://colllin-nips-2018-prosthetics/checkpoints/\",\n",
      "        \"policy_weights_basename\": \"checkpoint_TD3\",\n",
      "        \"rollout_refresh_model_freq\": 10\n",
      "    },\n",
      "    \"training\": {\n",
      "        \"#\": \"Frequency of delayed policy updates\",\n",
      "        \"eval_freq\": 5000.0,\n",
      "        \"batch_size\": 100,\n",
      "        \"discount\": 0.99,\n",
      "        \"tau\": 0.005,\n",
      "        \"policy_noise\": 0.2,\n",
      "        \"noise_clip\": 0.5,\n",
      "        \"policy_freq\": 2\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('config_distributed.json', 'r') as f:\n",
    "    CONFIG = json.load(f)\n",
    "print(json.dumps(CONFIG, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create simulation env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = ProstheticsEnvWithHistory(visualize=False, integrator_accuracy=CONFIG['env']['integrator_accuracy'])\n",
    "env_step_kwargs = {'project': False}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Policy, Download & load latest weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 19, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dim = env.observation_space.shape[0]\n",
    "env.reset(**env_step_kwargs)\n",
    "state_dim = prepare_model_observation(env).shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = int(env.action_space.high[0])\n",
    "state_dim, action_dim, max_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = TD3(state_dim, action_dim, max_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading policy checkpoints from s3://colllin-nips-2018-prosthetics/checkpoints/checkpoint_TD3*\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading policy checkpoints from {CONFIG['distributed']['policy_weights_dir_s3']}{CONFIG['distributed']['policy_weights_basename']}*\")\n",
    "load_s3_model_checkpoint(\n",
    "    policy, \n",
    "    s3_dir=CONFIG['distributed']['policy_weights_dir_s3'],\n",
    "    basename=CONFIG['distributed']['policy_weights_basename'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode Hacking (Custom \"done\" criteria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_abort_episode(env_obs, custom_rewards=None, verbose=False):\n",
    "#     print((np.array(env_obs['body_pos_rot']['torso'])*180/math.pi > 60).any())\n",
    "#     if env_obs['body_pos_rot']['torso'][2] < -0.2:\n",
    "#         return True\n",
    "    rewards = custom_rewards if custom_rewards != None else env_obs_to_custom_reward(env_obs)\n",
    "    # print(f'Custom reward: {sum(rewards.values())}')\n",
    "    if (env_obs['body_pos']['head'][0] - env_obs['body_pos']['pelvis'][0]) < -.2:\n",
    "        if verbose: print(f'Aborting episode due to head being > .2m behind the pelvis ({env_obs[\"body_pos\"][\"head\"][0] - env_obs[\"body_pos\"][\"pelvis\"][0]}).')\n",
    "        return True\n",
    "    if np.fabs(env_obs['body_pos']['head'][2]) > 0.5:\n",
    "        if verbose: print(f'Aborting episode due to head being > 0.5m away from centerline ({env_obs[\"body_pos\"][\"head\"][2]}).')\n",
    "        return True\n",
    "    if sum(rewards.values()) < -10:\n",
    "        if verbose:\n",
    "            print(f'Aborting episode due to custom reward < -10 ({sum(rewards.values())}):')\n",
    "            for k,v in rewards.items():\n",
    "                if v < 0:\n",
    "                    print(f'  reward `{k}` = {v}')\n",
    "        return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy rollout (Record & Persist Simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_timesteps = 0\n",
    "episode_num = 0\n",
    "done = True\n",
    "episode_timesteps = 0\n",
    "total_timesteps, episode_num, episode_timesteps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading policy checkpoint from s3://colllin-nips-2018-prosthetics/checkpoints/checkpoint_TD3\n",
      "Aborting episode due to head being > 0.5m away from centerline (0.5050897337861889).\n",
      "Total T: 101 Episode Num: 1 Episode T: 101 Reward: -119.65729951433863\n",
      "Aborting episode due to head being > 0.5m away from centerline (0.5025997258468484).\n",
      "Total T: 192 Episode Num: 2 Episode T: 91 Reward: -128.90716796662326\n",
      "Aborting episode due to head being > 0.5m away from centerline (0.5067625285241153).\n",
      "Total T: 281 Episode Num: 3 Episode T: 89 Reward: -130.864007089756\n",
      "Aborting episode due to head being > 0.5m away from centerline (0.5023494013316863).\n",
      "Total T: 372 Episode Num: 4 Episode T: 91 Reward: -130.6906252411301\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20330664563656037).\n",
      "Total T: 467 Episode Num: 5 Episode T: 95 Reward: -140.92169302885011\n",
      "Aborting episode due to head being > 0.5m away from centerline (0.5015272353303353).\n",
      "Total T: 558 Episode Num: 6 Episode T: 91 Reward: -129.3899931448503\n",
      "Aborting episode due to head being > 0.5m away from centerline (0.5084676227284326).\n",
      "Total T: 653 Episode Num: 7 Episode T: 95 Reward: -131.09815304603504\n",
      "Aborting episode due to head being > 0.5m away from centerline (0.5089960810327792).\n",
      "Total T: 736 Episode Num: 8 Episode T: 83 Reward: -205.3197508479992\n",
      "Aborting episode due to head being > 0.5m away from centerline (0.5069821251337628).\n",
      "Total T: 896 Episode Num: 9 Episode T: 160 Reward: -77.19175648324371\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20013632432893352).\n",
      "Total T: 1004 Episode Num: 10 Episode T: 108 Reward: -165.05123703320828\n",
      "Loading policy checkpoint from s3://colllin-nips-2018-prosthetics/checkpoints/checkpoint_TD3\n",
      "Aborting episode due to head being > 0.5m away from centerline (0.5023385230801215).\n",
      "Total T: 1095 Episode Num: 11 Episode T: 91 Reward: -131.89716098218437\n",
      "Aborting episode due to head being > .2m behind the pelvis (-0.20004632293752403).\n",
      "Total T: 1221 Episode Num: 12 Episode T: 126 Reward: -137.08240952539833\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function Manager_integrate> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/opensim/simbody.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m  17704\u001b[0m     \u001b[0m__swig_setmethods__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 17705\u001b[0;31m     \u001b[0m__setattr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_swig_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  17706\u001b[0m     \u001b[0m__swig_getmethods__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-491e0290c641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Perform action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_env_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0menv_step_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nips-2018-ai-for-prosthetics/environment/prosthetics_env_with_history.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProstheticsEnvWithHistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         self.append_history({\n\u001b[1;32m     29\u001b[0m             \u001b[0;34m'episode_uuid'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/osim/env/osim.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action, project)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_state_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mosim_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactuate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mosim_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/osim/env/osim.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m# Integrate till the new endtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mistep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/opensim/simulation.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, finalTime)\u001b[0m\n\u001b[1;32m  38432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  38433\u001b[0m         \"\"\"\n\u001b[0;32m> 38434\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_simulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mManager_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  38435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  38436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function Manager_integrate> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    if done: \n",
    "        if (episode_num % CONFIG['distributed']['rollout_refresh_model_freq']) == 0:\n",
    "            print(f\"\\nLoading policy checkpoint from {CONFIG['distributed']['policy_weights_dir_s3']}{CONFIG['distributed']['policy_weights_basename']}\\n\")\n",
    "            load_s3_model_checkpoint(\n",
    "                policy, \n",
    "                s3_dir=CONFIG['distributed']['policy_weights_dir_s3'],\n",
    "                basename=CONFIG['distributed']['policy_weights_basename'],\n",
    "            )\n",
    "            timesteps_since_model_update = 0\n",
    "            persist_event('rollout_model_refreshed', {\n",
    "                'episode_num': episode_num,\n",
    "            })\n",
    "\n",
    "        # Reset environment\n",
    "        obs = env.reset(**env_step_kwargs)\n",
    "        reset_frameskip(CONFIG['rollout']['frameskip'])\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        episode_timesteps = 0\n",
    "        episode_num += 1 \n",
    "\n",
    "    # # Select action randomly or according to policy\n",
    "    # if total_timesteps < CONFIG['training']['start_timesteps']:\n",
    "    #     action = env.action_space.sample()\n",
    "    # else:\n",
    "    action = policy.select_action(prepare_model_observation(env))\n",
    "    if CONFIG['rollout']['expl_noise'] != 0: \n",
    "        action = (action + np.random.normal(0, CONFIG['rollout']['expl_noise'], size=env.action_space.shape[0])).clip(env.action_space.low, env.action_space.high)\n",
    "\n",
    "    # Perform action\n",
    "    action = prepare_env_action(action)\n",
    "    obs, reward, done, _ = env.step(action, **env_step_kwargs)\n",
    "\n",
    "    if not done:\n",
    "        done = should_abort_episode(env.get_state_desc(), verbose=True)\n",
    "    done_bool = 0 if episode_timesteps + 1 == CONFIG['rollout']['max_episode_steps'] else float(done)\n",
    "\n",
    "    # custom_rewards = compute_rewards(new_obs_dict)\n",
    "    episode_reward += reward #+ sum(custom_rewards.values())\n",
    "\n",
    "    episode_timesteps += 1\n",
    "    total_timesteps += 1\n",
    "\n",
    "    if done:\n",
    "        # Persist timesteps to central database\n",
    "        persist_timesteps(env.history())\n",
    "        env.reset_history()\n",
    "\n",
    "        # Log episode\n",
    "        persist_event('rollout_episode_completed', {\n",
    "            'episode_num': episode_num,\n",
    "            'episode_timesteps': episode_timesteps,\n",
    "            'episode_reward': episode_reward,\n",
    "        })\n",
    "        print(f\"Total T: {total_timesteps} Episode Num: {episode_num} Episode T: {episode_timesteps} Reward: {episode_reward}\")\n",
    "        sys.stdout.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prosthetics",
   "language": "python",
   "name": "prosthetics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
