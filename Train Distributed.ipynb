{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import uuid\n",
    "import datetime\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from models.td3 import TD3\n",
    "# from osim.env import ProstheticsEnv\n",
    "from environment.prosthetics_env_with_history import ProstheticsEnvWithHistory\n",
    "from environment.observations import prepare_model_observation, env_obs_history_to_model_obs\n",
    "from environment.actions import prepare_env_action, reset_frameskip\n",
    "from environment.rewards import env_obs_to_custom_reward\n",
    "from distributed.database import persist_timesteps, persist_event, get_total_timesteps, clear_clients_for_thread\n",
    "from distributed.db_history_sampler import DatabaseHistorySampler\n",
    "from distributed.s3_checkpoints import load_s3_model_checkpoint, save_s3_model_checkpoint\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"env\": {\n",
      "        \"integrator_accuracy\": 0.002\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"architecture\": \"TD3\"\n",
      "    },\n",
      "    \"rollout\": {\n",
      "        \"#\": \"Frameskip will be applied for random durations between 0 and `frameskip` timesteps.\",\n",
      "        \"max_episode_steps\": 600,\n",
      "        \"expl_noise\": 0.25,\n",
      "        \"frameskip\": 5\n",
      "    },\n",
      "    \"distributed\": {\n",
      "        \"policy_weights_dir_s3\": \"s3://colllin-nips-2018-prosthetics/checkpoints/\",\n",
      "        \"policy_weights_basename\": \"checkpoint_TD3\",\n",
      "        \"#\": \"How often (episodes) we download model weights during rollout.\",\n",
      "        \"rollout_refresh_model_freq\": 5\n",
      "    },\n",
      "    \"training\": {\n",
      "        \"#\": \"Frequency of delayed policy updates\",\n",
      "        \"eval_freq\": 2000,\n",
      "        \"batch_size\": 100,\n",
      "        \"discount\": 0.99,\n",
      "        \"tau\": 0.005,\n",
      "        \"policy_noise\": 0.2,\n",
      "        \"noise_clip\": 0.5,\n",
      "        \"policy_freq\": 2\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('config_distributed.json', 'r') as f:\n",
    "    CONFIG = json.load(f)\n",
    "print(json.dumps(CONFIG, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Policy, Download & load latest weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1260, 19, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dim = env.observation_space.shape[0]\n",
    "env = ProstheticsEnvWithHistory(visualize=False, integrator_accuracy=CONFIG['env']['integrator_accuracy'])\n",
    "env.reset()\n",
    "state_dim = prepare_model_observation(env).shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = int(env.action_space.high[0])\n",
    "del env\n",
    "state_dim, action_dim, max_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = TD3(state_dim, action_dim, max_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading policy checkpoints from s3://colllin-nips-2018-prosthetics/checkpoints/checkpoint_TD3*\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading policy checkpoints from {CONFIG['distributed']['policy_weights_dir_s3']}{CONFIG['distributed']['policy_weights_basename']}*\")\n",
    "load_s3_model_checkpoint(\n",
    "    policy, \n",
    "    s3_dir=CONFIG['distributed']['policy_weights_dir_s3'],\n",
    "    basename=CONFIG['distributed']['policy_weights_basename'],\n",
    ")\n",
    "persist_event('train_load_latest_checkpoint', f'Loaded policy checkpoint from {CONFIG[\"distributed\"][\"policy_weights_dir_s3\"]}{CONFIG[\"distributed\"][\"policy_weights_basename\"]}*')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode Hacking (Custom \"done\" criteria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_abort_episode(env_obs, custom_rewards=None, verbose=False):\n",
    "#     print((np.array(env_obs['body_pos_rot']['torso'])*180/math.pi > 60).any())\n",
    "#     if env_obs['body_pos_rot']['torso'][2] < -0.2:\n",
    "#         return True\n",
    "    rewards = custom_rewards if custom_rewards != None else env_obs_to_custom_reward(env_obs)\n",
    "    # print(f'Custom reward: {sum(rewards.values())}')\n",
    "    if (env_obs['body_pos']['head'][0] - env_obs['body_pos']['pelvis'][0]) < -.2:\n",
    "        if verbose: print(f'Aborting episode due to head being > .2m behind the pelvis ({env_obs[\"body_pos\"][\"head\"][0] - env_obs[\"body_pos\"][\"pelvis\"][0]}).')\n",
    "        return True\n",
    "    if np.fabs(env_obs['body_pos']['head'][2]) > 0.5:\n",
    "        if verbose: print(f'Aborting episode due to head being > 0.5m away from centerline ({env_obs[\"body_pos\"][\"head\"][2]}).')\n",
    "        return True\n",
    "    if sum(rewards.values()) < -10:\n",
    "        if verbose:\n",
    "            print(f'Aborting episode due to custom reward < -10 ({sum(rewards.values())}):')\n",
    "            for k,v in rewards.items():\n",
    "                if v < 0:\n",
    "                    print(f'  reward `{k}` = {v}')\n",
    "        return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_sampler = DatabaseHistorySampler(\n",
    "    env_obs_history_to_model_obs_fn=env_obs_history_to_model_obs, \n",
    "    n_obs_history=3,\n",
    "    env_obs_custom_reward_fn=lambda obs: sum(env_obs_to_custom_reward(obs).values()),\n",
    "    env_obs_custom_done_fn=should_abort_episode,\n",
    ")\n",
    "\n",
    "def load_batch(fake_batch):\n",
    "    return history_sampler.sample(len(fake_batch))\n",
    "\n",
    "fake_dataset_len = CONFIG['training']['eval_freq'] * CONFIG['training']['batch_size']\n",
    "fake_dataset = list(range(int(fake_dataset_len)))\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    fake_dataset,\n",
    "    batch_size=CONFIG['training']['batch_size'], \n",
    "#     shuffle=False, \n",
    "#     sampler=None, \n",
    "#     batch_sampler=None, \n",
    "    num_workers=6, \n",
    "    collate_fn=load_batch, \n",
    "    pin_memory=True, \n",
    "    drop_last=True, \n",
    "#     timeout=0, \n",
    "    worker_init_fn=lambda instance_id: clear_clients_for_thread()\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train model: 100%|██████████| 2000/2000 [04:41<00:00,  7.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAving policy checkpoints to s3://colllin-nips-2018-prosthetics/checkpoints/checkpoint_TD3*\n",
      "SAving policy checkpoints to s3://colllin-nips-2018-prosthetics/checkpoints/checkpoint_TD3_T27221_2018-09-25T18:40:23.718494*\n",
      "SAving policy checkpoints to 926d23b3-0e17-47c8-a33a-d8bdc4c51005/checkpoint_TD3_T27221_2018-09-25T18:40:23.718494*\n",
      "Launching evaluation script with cmd: `CHECKPOINT_DIR=926d23b3-0e17-47c8-a33a-d8bdc4c51005 CHECKPOINT_NAME=checkpoint_TD3_T27221_2018-09-25T18:40:23.718494 pipenv run python evaluate_policy.py`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train model: 100%|██████████| 2000/2000 [05:42<00:00,  5.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAving policy checkpoints to s3://colllin-nips-2018-prosthetics/checkpoints/checkpoint_TD3*\n",
      "SAving policy checkpoints to s3://colllin-nips-2018-prosthetics/checkpoints/checkpoint_TD3_T27221_2018-09-25T18:46:08.955179*\n",
      "SAving policy checkpoints to 52fd7daa-c297-418b-b9e6-bf828b6c8462/checkpoint_TD3_T27221_2018-09-25T18:46:08.955179*\n",
      "Launching evaluation script with cmd: `CHECKPOINT_DIR=52fd7daa-c297-418b-b9e6-bf828b6c8462 CHECKPOINT_NAME=checkpoint_TD3_T27221_2018-09-25T18:46:08.955179 pipenv run python evaluate_policy.py`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train model: 100%|██████████| 2000/2000 [06:40<00:00,  4.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAving policy checkpoints to s3://colllin-nips-2018-prosthetics/checkpoints/checkpoint_TD3*\n",
      "SAving policy checkpoints to s3://colllin-nips-2018-prosthetics/checkpoints/checkpoint_TD3_T27221_2018-09-25T18:52:51.850118*\n",
      "SAving policy checkpoints to a70b2283-8055-4387-a99d-1c146edaa8ae/checkpoint_TD3_T27221_2018-09-25T18:52:51.850118*\n",
      "Launching evaluation script with cmd: `CHECKPOINT_DIR=a70b2283-8055-4387-a99d-1c146edaa8ae CHECKPOINT_NAME=checkpoint_TD3_T27221_2018-09-25T18:52:51.850118 pipenv run python evaluate_policy.py`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train model: 100%|██████████| 2000/2000 [06:59<00:00,  7.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAving policy checkpoints to s3://colllin-nips-2018-prosthetics/checkpoints/checkpoint_TD3*\n",
      "SAving policy checkpoints to s3://colllin-nips-2018-prosthetics/checkpoints/checkpoint_TD3_T28572_2018-09-25T18:59:53.464152*\n",
      "SAving policy checkpoints to db33dd0b-1c31-48ea-9cb7-a03f84499f1d/checkpoint_TD3_T28572_2018-09-25T18:59:53.464152*\n",
      "Launching evaluation script with cmd: `CHECKPOINT_DIR=db33dd0b-1c31-48ea-9cb7-a03f84499f1d CHECKPOINT_NAME=checkpoint_TD3_T28572_2018-09-25T18:59:53.464152 pipenv run python evaluate_policy.py`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train model:  70%|██████▉   | 1390/2000 [05:02<02:26,  4.18batch/s]Process Process-26:\n",
      "Process Process-30:\n",
      "Process Process-25:\n",
      "Process Process-28:\n",
      "Process Process-29:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-7-7dbbadf99dd8>\", line 9, in load_batch\n",
      "    return history_sampler.sample(len(fake_batch))\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/distributed/db_history_sampler.py\", line 15, in sample\n",
      "    docs_with_history = sample_timesteps(n=batch_size, n_obs_history=self.aggregate_obs_history)\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/distributed/database.py\", line 93, in sample_timesteps\n",
      "    for pt in past_timesteps:\n",
      "  File \"<ipython-input-7-7dbbadf99dd8>\", line 9, in load_batch\n",
      "    return history_sampler.sample(len(fake_batch))\n",
      "  File \"<ipython-input-7-7dbbadf99dd8>\", line 9, in load_batch\n",
      "    return history_sampler.sample(len(fake_batch))\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/distributed/db_history_sampler.py\", line 15, in sample\n",
      "    docs_with_history = sample_timesteps(n=batch_size, n_obs_history=self.aggregate_obs_history)\n",
      "  File \"<ipython-input-7-7dbbadf99dd8>\", line 9, in load_batch\n",
      "    return history_sampler.sample(len(fake_batch))\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/distributed/database.py\", line 69, in sample_timesteps\n",
      "    '$limit': n\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/distributed/db_history_sampler.py\", line 28, in sample\n",
      "    R = [self.env_obs_custom_reward_fn(d['obs']) for d in docs_with_history]\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/cursor.py\", line 1189, in next\n",
      "    if len(self.__data) or self._refresh():\n",
      "  File \"<ipython-input-7-7dbbadf99dd8>\", line 9, in load_batch\n",
      "    return history_sampler.sample(len(fake_batch))\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/distributed/db_history_sampler.py\", line 35, in sample\n",
      "    X = [self.env_obs_history_to_model_obs_fn(obslist(d)[:-1]) for d in docs_with_history]\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/distributed/db_history_sampler.py\", line 28, in <listcomp>\n",
      "    R = [self.env_obs_custom_reward_fn(d['obs']) for d in docs_with_history]\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/collection.py\", line 2397, in aggregate\n",
      "    **kwargs)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/cursor.py\", line 1126, in _refresh\n",
      "    self.__send_message(g)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/cursor.py\", line 978, in __send_message\n",
      "    codec_options=self.__codec_options)\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/distributed/db_history_sampler.py\", line 35, in <listcomp>\n",
      "    X = [self.env_obs_history_to_model_obs_fn(obslist(d)[:-1]) for d in docs_with_history]\n",
      "  File \"<ipython-input-7-7dbbadf99dd8>\", line 4, in <lambda>\n",
      "    env_obs_custom_reward_fn=lambda obs: sum(env_obs_to_custom_reward(obs).values()),\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/collection.py\", line 2304, in _aggregate\n",
      "    client=self.__database.client)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/cursor.py\", line 1067, in _unpack_response\n",
      "    return response.unpack_response(cursor_id, codec_options)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/distributed/db_history_sampler.py\", line 15, in sample\n",
      "    docs_with_history = sample_timesteps(n=batch_size, n_obs_history=self.aggregate_obs_history)\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/environment/observations.py\", line 384, in env_obs_history_to_model_obs\n",
      "    model_obs_steps += [single_step_env_obs_to_model_obs(env_obs, exclude_lower_order_values=True) for env_obs in env_obs_history[:-1]][::-1]\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/message.py\", line 1463, in unpack_response\n",
      "    return bson.decode_all(self.payload_document, codec_options)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/pool.py\", line 584, in command\n",
      "    self._raise_connection_failure(error)\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/environment/observations.py\", line 384, in <listcomp>\n",
      "    model_obs_steps += [single_step_env_obs_to_model_obs(env_obs, exclude_lower_order_values=True) for env_obs in env_obs_history[:-1]][::-1]\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/pool.py\", line 745, in _raise_connection_failure\n",
      "    raise error\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/distributed/database.py\", line 93, in sample_timesteps\n",
      "    for pt in past_timesteps:\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/bson/timestamp.py\", line 51, in __init__\n",
      "    if isinstance(time, datetime.datetime):\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/environment/observations.py\", line 306, in single_step_env_obs_to_model_obs\n",
      "    env_obs['body_vel'][k] = list(np.array(vel) - frame['vel'])\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/pool.py\", line 579, in command\n",
      "    unacknowledged=unacknowledged)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/cursor.py\", line 1189, in next\n",
      "    if len(self.__data) or self._refresh():\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/network.py\", line 142, in command\n",
      "    unpacked_docs = reply.unpack_response(codec_options=codec_options)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/cursor.py\", line 1126, in _refresh\n",
      "    self.__send_message(g)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/pool.py\", line 745, in _raise_connection_failure\n",
      "    raise error\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/pool.py\", line 612, in receive_message\n",
      "    self._raise_connection_failure(error)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/cursor.py\", line 931, in __send_message\n",
      "    operation, exhaust=self.__exhaust, address=self.__address)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/mongo_client.py\", line 1145, in _send_message_with_response\n",
      "    exhaust)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/mongo_client.py\", line 1156, in _reset_on_error\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/server.py\", line 106, in send_message_with_response\n",
      "    reply = sock_info.receive_message(request_id)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/pool.py\", line 610, in receive_message\n",
      "    self.max_message_size)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/message.py\", line 1463, in unpack_response\n",
      "    return bson.decode_all(self.payload_document, codec_options)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/network.py\", line 191, in receive_message\n",
      "    data = _receive_data_on_socket(sock, length - 16)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/bson/objectid.py\", line 83, in __init__\n",
      "    def __init__(self, oid=None):\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/network.py\", line 232, in _receive_data_on_socket\n",
      "    chunk_length = sock.recv_into(mv[bytes_read:])\n",
      "KeyboardInterrupt\n",
      "Process Process-27:\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/ssl.py\", line 1009, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/ssl.py\", line 871, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/ssl.py\", line 631, in read\n",
      "    v = self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-7-7dbbadf99dd8>\", line 9, in load_batch\n",
      "    return history_sampler.sample(len(fake_batch))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-28c7e80da0cf>\", line 10, in <module>\n",
      "    CONFIG['training']['policy_freq'],\n",
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/models/td3.py\", line 111, in train\n",
      "    for ibatch, (x, y, u, r, d) in enumerate(tqdm(iter(replay_dataloader), desc='Train model', unit='batch')):\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 937, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 330, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 309, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/usr/lib/python3.6/queue.py\", line 164, in get\n",
      "    self.not_empty.wait()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/posixpath.py\", line 421, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/posixpath.py\", line 81, in join\n",
      "    sep = _get_sep(a)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/posixpath.py\", line 42, in _get_sep\n",
      "    if isinstance(path, bytes):\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 7800) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/distributed/db_history_sampler.py\", line 15, in sample\n",
      "    docs_with_history = sample_timesteps(n=batch_size, n_obs_history=self.aggregate_obs_history)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ubuntu/nips-2018-ai-for-prosthetics/distributed/database.py\", line 93, in sample_timesteps\n",
      "    for pt in past_timesteps:\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/cursor.py\", line 1189, in next\n",
      "    if len(self.__data) or self._refresh():\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/cursor.py\", line 1126, in _refresh\n",
      "    self.__send_message(g)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/cursor.py\", line 978, in __send_message\n",
      "    codec_options=self.__codec_options)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/cursor.py\", line 1067, in _unpack_response\n",
      "    return response.unpack_response(cursor_id, codec_options)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/pymongo/message.py\", line 1463, in unpack_response\n",
      "    return bson.decode_all(self.payload_document, codec_options)\n",
      "  File \"/home/ubuntu/.local/share/virtualenvs/nips-2018-ai-for-prosthetics-fCqIkKV7/lib/python3.6/site-packages/bson/timestamp.py\", line 33, in __init__\n",
      "    def __init__(self, time, inc):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Train for `eval_freq` batches:\n",
    "    if CONFIG['model']['architecture'] == \"TD3\":\n",
    "        policy.train(\n",
    "            dataloader,\n",
    "            CONFIG['training']['discount'], \n",
    "            CONFIG['training']['tau'], \n",
    "            CONFIG['training']['policy_noise'], \n",
    "            CONFIG['training']['noise_clip'], \n",
    "            CONFIG['training']['policy_freq'],\n",
    "        )\n",
    "    else: \n",
    "        policy.train(\n",
    "            history_sampler,#replay_buffer, \n",
    "            int(CONFIG['training']['eval_freq']),\n",
    "            CONFIG['training']['batch_size'], \n",
    "            CONFIG['training']['discount'], \n",
    "            CONFIG['training']['tau']\n",
    "        )\n",
    "    persist_event('train_epoch_completed', f'Trained policy for {len(dataloader)} batches of {dataloader.batch_size}')\n",
    "      \n",
    "    # Upload policy weights to S3, to be picked up by instances running the Rollout Distributed process.\n",
    "    print(f\"SAving policy checkpoints to {CONFIG['distributed']['policy_weights_dir_s3']}{CONFIG['distributed']['policy_weights_basename']}*\")\n",
    "    save_s3_model_checkpoint(\n",
    "        policy, \n",
    "        s3_dir=CONFIG['distributed']['policy_weights_dir_s3'],\n",
    "        basename=CONFIG['distributed']['policy_weights_basename'],\n",
    "    )\n",
    "    persist_event('train_update_s3_checkpoint', f'Uploaded policy checkpoint to {CONFIG[\"distributed\"][\"policy_weights_dir_s3\"]}{CONFIG[\"distributed\"][\"policy_weights_basename\"]}*')\n",
    "    \n",
    "    # Also upload policy weights under unique name as a historical checkpoint.\n",
    "    total_timesteps = get_total_timesteps()\n",
    "    evalname = f\"{CONFIG['distributed']['policy_weights_basename']}_T{total_timesteps}_{datetime.datetime.now().isoformat()}\"\n",
    "    print(f\"SAving policy checkpoints to {CONFIG['distributed']['policy_weights_dir_s3']}{evalname}*\")\n",
    "    save_s3_model_checkpoint(\n",
    "        policy, \n",
    "        s3_dir=CONFIG['distributed']['policy_weights_dir_s3'],\n",
    "        basename=evalname,\n",
    "    )\n",
    "    persist_event('train_save_historical_checkpoint', f'Uploaded policy checkpoint to {CONFIG[\"distributed\"][\"policy_weights_dir_s3\"]}{evalname}*')\n",
    "\n",
    "    # Run Evaluation script\n",
    "    evaldir = str(uuid.uuid4())\n",
    "    print(f\"SAving policy checkpoints to {evaldir}/{evalname}*\")\n",
    "    os.makedirs(evaldir, exist_ok=True)\n",
    "    policy.save(evaldir, evalname)\n",
    "    evalcmd = f\"CHECKPOINT_DIR={evaldir} CHECKPOINT_NAME={evalname} pipenv run python evaluate_policy.py\"\n",
    "    print(f\"Launching evaluation script with cmd: `{evalcmd}`\")\n",
    "    subprocess.Popen(evalcmd, shell=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prosthetics",
   "language": "python",
   "name": "prosthetics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
